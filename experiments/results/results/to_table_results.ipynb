{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "54618e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[ht]\n",
      "\\centering\n",
      "\\small\n",
      "\\caption{Marginal coverage when conformalizing with missing outputs (desired coverage 0.9).}\n",
      "\\resizebox{\\linewidth}{!}{\n",
      "\\begin{tabular}{l|cc|cc}\n",
      "\\hline\n",
      "Dataset & \\multicolumn{2}{c|}{Missing at random} & \\multicolumn{2}{c}{10\\% extreme removed} \\\\ \n",
      " & With missing & Full output & With missing & Full output \\\\ \\hline\n",
      "Bias & $90.4 \\pm 1.1$ & $85.1 \\pm 1.7$ & $90.8 \\pm 1.2$ & $90.7 \\pm 1.1$ \\\\ \\hline\n",
      "CASP & $89.8 \\pm 0.7$ & $89.3 \\pm 0.9$ & $90.2 \\pm 0.4$ & $89.7 \\pm 0.4$ \\\\ \\hline\n",
      "House & $89.7 \\pm 1.1$ & $87.9 \\pm 1.3$ & $89.6 \\pm 1.0$ & $87.6 \\pm 0.9$ \\\\ \\hline\n",
      "rf1 & $90.7 \\pm 1.2$ & $89.0 \\pm 1.6$ & $90.4 \\pm 1.3$ & $89.2 \\pm 1.3$ \\\\ \\hline\n",
      "rf2 & $90.5 \\pm 1.5$ & $89.1 \\pm 1.5$ & $90.1 \\pm 1.2$ & $88.7 \\pm 1.2$ \\\\ \\hline\n",
      "scm1d & $89.9 \\pm 0.7$ & $81.3 \\pm 2.1$ & $89.8 \\pm 1.4$ & $86.9 \\pm 1.9$ \\\\ \\hline\n",
      "scm20d & $89.9 \\pm 1.2$ & $81.4 \\pm 2.2$ & $89.6 \\pm 1.4$ & $85.5 \\pm 1.3$ \\\\ \\hline\n",
      "Taxi & $89.9 \\pm 0.5$ & $89.3 \\pm 0.7$ & $90.0 \\pm 0.6$ & $82.7 \\pm 0.6$ \\\\ \\hline\n",
      "\\end{tabular}\n",
      "}\n",
      "\\label{tab:coverage:missing:0.9}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load both datasets\n",
    "df_missing = pd.read_csv(\"results_missing.csv\")\n",
    "df_extreme = pd.read_csv(\"results_missing_extreme.csv\")\n",
    "\n",
    "# 2. Define a helper function to process dataframes identically\n",
    "def get_grouped_stats(df, alpha=0.1):\n",
    "    # Filter alpha\n",
    "    df_filtered = df[df[\"alpha\"] == alpha]\n",
    "    # Compute mean and std per dataset\n",
    "    return (\n",
    "        df_filtered.groupby(\"dataset\")[[\"coverage_nan\", \"coverage_full\"]]\n",
    "        .agg([\"mean\", \"std\"])\n",
    "    )\n",
    "\n",
    "# Calculate stats for both scenarios\n",
    "stats_missing = get_grouped_stats(df_missing)\n",
    "stats_extreme = get_grouped_stats(df_extreme)\n",
    "\n",
    "# 3. Define formatting function\n",
    "def fmt(mean, std):\n",
    "    # Formats as \"95.0 \\pm 1.2\"\n",
    "    return f\"${100*mean:.1f} \\\\pm {100*std:.1f}$\"\n",
    "\n",
    "name_map = {\n",
    "    \"biais\": \"Bias\",\n",
    "    \"casp\": \"CASP\",\n",
    "    \"house\": \"House\",\n",
    "    \"rf1\": \"rf1\",\n",
    "    \"rf2\": \"rf2\",\n",
    "    \"scm1d\": \"scm1d\",\n",
    "    \"scm20d\": \"scm20d\",\n",
    "    \"taxi\": \"Taxi\",\n",
    "}\n",
    "\n",
    "# 4. Construct the LaTeX Table\n",
    "latex = \"\"\n",
    "latex += \"\\\\begin{table}[ht]\\n\"\n",
    "latex += \"\\\\centering\\n\"\n",
    "latex += \"\\\\small\\n\"\n",
    "latex += \"\\\\caption{Marginal coverage when conformalizing with missing outputs (desired coverage 0.9).}\\n\"\n",
    "latex += \"\\\\resizebox{\\linewidth}{!}{\\n\"\n",
    "# {l|cc|cc} creates vertical lines between the Dataset and the two main groups\n",
    "latex += \"\\\\begin{tabular}{l|cc|cc}\\n\"\n",
    "latex += \"\\\\hline\\n\"\n",
    "\n",
    "# --- Header Row 1: The Main Groups ---\n",
    "# \\multicolumn{2}{c|}{...} spans 2 columns and adds a vertical line after\n",
    "latex += \"Dataset & \\\\multicolumn{2}{c|}{Missing at random} & \\\\multicolumn{2}{c}{10\\\\% extreme removed} \\\\\\\\ \\n\"\n",
    "\n",
    "# --- Header Row 2: The Sub-columns ---\n",
    "latex += \" & With missing & Full output & With missing & Full output \\\\\\\\ \\\\hline\\n\"\n",
    "\n",
    "# 5. Populate Rows\n",
    "# We iterate through the index of one stats object (assuming datasets match in both files)\n",
    "for dataset in stats_missing.index:\n",
    "    # Clean up name using the map\n",
    "    clean_name = name_map.get(dataset.lower(), dataset.capitalize())\n",
    "    \n",
    "    # Extract 'Missing at random' stats\n",
    "    m_nan = fmt(stats_missing.loc[dataset, (\"coverage_nan\", \"mean\")], \n",
    "                stats_missing.loc[dataset, (\"coverage_nan\", \"std\")])\n",
    "    m_full = fmt(stats_missing.loc[dataset, (\"coverage_full\", \"mean\")], \n",
    "                 stats_missing.loc[dataset, (\"coverage_full\", \"std\")])\n",
    "    \n",
    "    # Extract 'Extreme removed' stats\n",
    "    e_nan = fmt(stats_extreme.loc[dataset, (\"coverage_nan\", \"mean\")], \n",
    "                stats_extreme.loc[dataset, (\"coverage_nan\", \"std\")])\n",
    "    e_full = fmt(stats_extreme.loc[dataset, (\"coverage_full\", \"mean\")], \n",
    "                 stats_extreme.loc[dataset, (\"coverage_full\", \"std\")])\n",
    "\n",
    "    # Append row to LaTeX string\n",
    "    latex += f\"{clean_name} & {m_nan} & {m_full} & {e_nan} & {e_full} \\\\\\\\ \\\\hline\\n\"\n",
    "\n",
    "# 6. Close Table\n",
    "latex += \"\\\\end{tabular}\\n\"\n",
    "latex += \"}\\n\"\n",
    "latex += \"\\\\label{tab:coverage:missing:0.9}\\n\"\n",
    "latex += \"\\\\end{table}\"\n",
    "\n",
    "print(latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc5f5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[ht]\n",
      "\\centering\n",
      "\\small\n",
      "\\caption{Comparison of conditional coverage ($\\alpha=0.1$) for different conformal methods using the ERT metric (lower is better) and WSC (closer to $0.9$ is better) and the running time to calibrate the predictions. Best values in bold, second best underlined. N/A indicates that the method failed to produce valid results for the corresponding dataset due to poor conditional density estimation leading to numerical issues in high dimensions}\n",
      "\\resizebox{\\linewidth}{!}{\n",
      "\\begin{tabular}{l l c c c c c }\n",
      "\\hline\n",
      "{\\begin{tabular}{c} Dataset \\\\ {\\small [output dim]} \\end{tabular}} & Metric & Mahalanobis & HPD & ECM & OT & MVCS \\\\\n",
      "\\hline\n",
      "\\multirow{3}{*}{{Bias [2]}} & ERT [\\%] & \\textbf{1.68} & \\underline{2.00} & 3.72 & 3.69 & 3.05 \\\\\n",
      " & WSC & 0.72 & 0.72 & 0.72 & \\textbf{0.73} & \\underline{0.72} \\\\\n",
      " & Time [s] & \\underline{0.06} & 556.89 & \\textbf{0.01} & 19.91 & 0.12 \\\\\n",
      "\\hline\n",
      "\\multirow{3}{*}{{CASP [2]}} & ERT [\\%] & \\underline{1.89} & \\textbf{1.52} & 4.64 & 4.32 & 2.31 \\\\\n",
      " & WSC & \\underline{0.82} & \\textbf{0.84} & 0.80 & 0.80 & 0.82 \\\\\n",
      " & Time [s] & \\underline{0.05} & 2005.97 & \\textbf{0.02} & 2.52 & 0.45 \\\\\n",
      "\\hline\n",
      "\\multirow{3}{*}{{House [2]}} & ERT [\\%] & \\underline{3.01} & \\textbf{2.52} & 6.54 & 6.56 & 6.84 \\\\\n",
      " & WSC & \\underline{0.77} & \\textbf{0.80} & 0.72 & 0.72 & 0.71 \\\\\n",
      " & Time [s] & \\underline{0.04} & 1549.27 & \\textbf{0.01} & 0.48 & 0.15 \\\\\n",
      "\\hline\n",
      "\\multirow{3}{*}{{rf1 [8]}} & ERT [\\%] & \\textbf{3.02} & 4.70 & 11.24 & \\underline{3.30} & 9.62 \\\\\n",
      " & WSC & \\underline{0.73} & \\textbf{0.74} & 0.53 & 0.73 & 0.55 \\\\\n",
      " & Time [s] & \\underline{0.04} & 460.26 & \\textbf{0.01} & 18.98 & 0.14 \\\\\n",
      "\\hline\n",
      "\\multirow{3}{*}{{rf2 [8]}} & ERT [\\%] & \\textbf{3.36} & \\underline{4.73} & 9.92 & 5.84 & 8.37 \\\\\n",
      " & WSC & \\underline{0.73} & 0.73 & 0.72 & \\textbf{0.74} & 0.71 \\\\\n",
      " & Time [s] & \\underline{0.03} & 636.24 & \\textbf{0.01} & 35.04 & 0.07 \\\\\n",
      "\\hline\n",
      "\\multirow{3}{*}{{scm1d [16]}} & ERT [\\%] & \\textbf{3.01} & N/A & 12.33 & \\underline{3.60} & 11.43 \\\\\n",
      " & WSC & \\textbf{0.73} & N/A & 0.57 & \\underline{0.73} & 0.57 \\\\\n",
      " & Time [s] & \\underline{0.05} & N/A & \\textbf{0.01} & 22.68 & 0.08 \\\\\n",
      "\\hline\n",
      "\\multirow{3}{*}{{scm20d [16]}} & ERT [\\%] & \\textbf{1.39} & N/A & 9.29 & \\underline{2.91} & 8.99 \\\\\n",
      " & WSC & \\underline{0.74} & N/A & 0.70 & \\textbf{0.75} & 0.70 \\\\\n",
      " & Time [s] & 0.16 & N/A & \\textbf{0.01} & 27.74 & \\underline{0.08} \\\\\n",
      "\\hline\n",
      "\\multirow{3}{*}{{Taxi [2]}} & ERT [\\%] & \\textbf{0.64} & \\underline{0.76} & 2.77 & 3.68 & 2.30 \\\\\n",
      " & WSC & \\underline{0.84} & \\textbf{0.85} & 0.80 & 0.75 & 0.82 \\\\\n",
      " & Time [s] & \\underline{0.06} & 2596.51 & \\textbf{0.02} & 4.67 & 0.55 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "}\n",
      "\\label{tab:results_alpha01}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "alpha = 0.1\n",
    "\n",
    "df = pd.read_csv(\"results_full.csv\")\n",
    "\n",
    "\n",
    "\n",
    "mask = df[\"coverage_HDR\"] == 1.0\n",
    "df.loc[mask, [\"coverage_HDR\", \"ERT_HDR\", \"WSC_HDR\", \"volume_HDR\", \"time_HDR\"]] = np.nan\n",
    "\n",
    "\n",
    "methods = [\"levelset\", \"HDR\", \"one\", \"ot\", \"MVCS\"]\n",
    "\n",
    "# dataset name mapping\n",
    "dataset_map = {\n",
    "    \"biais\": \"Bias [2]\",\n",
    "    \"casp\": \"CASP [2]\",\n",
    "    \"house\": \"House [2]\",\n",
    "    \"rf1\": \"rf1 [8]\",\n",
    "    \"rf2\": \"rf2 [8]\",\n",
    "    \"scm1d\": \"scm1d [16]\",\n",
    "    \"scm20d\": \"scm20d [16]\",\n",
    "    \"taxi\": \"Taxi [2]\",\n",
    "}\n",
    "\n",
    "# method name mapping (for LaTeX header)\n",
    "method_map = {\n",
    "    \"levelset\": \"Mahalanobis\",\n",
    "    \"HDR\": \"HPD\",\n",
    "    \"one\": \"ECM\",\n",
    "    \"ot\": \"OT\",\n",
    "    \"MVCS\": \"MVCS\",\n",
    "}\n",
    "\n",
    "# keep alpha = 0.1 and compute means\n",
    "res = (\n",
    "    df[df[\"alpha\"] == alpha]\n",
    "    .groupby(\"dataset\", as_index=False)\n",
    "    .agg(lambda s: np.nan if s.isna().sum() > 2 else s.mean())\n",
    ")\n",
    "\n",
    "def format_row(values, mode=\"min\"):\n",
    "    \"\"\"\n",
    "    mode=\"min\": smallest bold, second smallest underlined\n",
    "    mode=\"max\": largest bold, second largest underlined\n",
    "    \"\"\"\n",
    "    vals = np.array(values, dtype=float)\n",
    "\n",
    "    if mode == \"min\":\n",
    "        order = np.argsort(vals)\n",
    "    else:\n",
    "        order = np.argsort(-vals)\n",
    "\n",
    "    best, second = order[0], order[1]\n",
    "\n",
    "    out = []\n",
    "    for i, v in enumerate(vals):\n",
    "        if np.isnan(v):\n",
    "            s = \"N/A\"\n",
    "            out.append(s)\n",
    "        else:\n",
    "            s = f\"{v:.2f}\"\n",
    "            if mode is not None:\n",
    "                if i == best:\n",
    "                    s = f\"\\\\textbf{{{s}}}\"\n",
    "                elif i == second:\n",
    "                    s = f\"\\\\underline{{{s}}}\"\n",
    "            out.append(s)\n",
    "    return out\n",
    "\n",
    "\n",
    "# ===== Build LaTeX table =====latex += f\"\\\\caption{{Comparison of methods for $\\\\alpha={alpha}$. Best values in bold, second best underlined.}}\\n\"\n",
    "\n",
    "\n",
    "header_methods = \" & \".join(method_map[m] for m in methods)\n",
    "\n",
    "latex = \"\"\n",
    "latex += \"\\\\begin{table}[ht]\\n\"\n",
    "latex += \"\\\\centering\\n\"\n",
    "latex += \"\\\\small\\n\"\n",
    "latex += f\"\\\\caption{{Comparison of conditional coverage ($\\\\alpha=0.1$) for different conformal methods using the ERT metric (lower is better) and WSC (closer to $0.9$ is better) and the running time to calibrate the predictions. Best values in bold, second best underlined. N/A indicates that the method failed to produce valid results for the corresponding dataset due to poor conditional density estimation leading to numerical issues in high dimensions}}\\n\"\n",
    "latex += \"\\\\resizebox{\\linewidth}{!}{\\n\"\n",
    "latex += \"\\\\begin{tabular}{l l \" + \"c \" * len(methods) + \"}\\n\"\n",
    "latex += \"\\\\hline\\n\"\n",
    "latex += f\"{{\\\\begin{{tabular}}{{c}} Dataset \\\\\\\\ {{\\small [output dim]}} \\\\end{{tabular}}}} & Metric & {header_methods} \\\\\\\\\\n\"\n",
    "latex += \"\\\\hline\\n\"\n",
    "\n",
    "for _, row in res.iterrows():\n",
    "    dataset_raw = row[\"dataset\"]\n",
    "    dataset = dataset_map.get(dataset_raw, dataset_raw)\n",
    "\n",
    "    # ert = [row[f\"ERT_{m}\"]*100 for m in methods]\n",
    "    # vol = [row[f\"volume_{m}\"] for m in methods]\n",
    "    # wsc = [row[f\"WSC_{m}\"] for m in methods]\n",
    "    # cov = [row[f\"coverage_{m}\"] for m in methods]\n",
    "    ert = [row.get(f\"ERT_{m}\", np.nan) * 100 if f\"ERT_{m}\" in row else np.nan for m in methods]\n",
    "    vol = [row.get(f\"volume_{m}\", np.nan) for m in methods]\n",
    "    wsc = [row.get(f\"WSC_{m}\", np.nan) for m in methods]\n",
    "    cov = [row.get(f\"coverage_{m}\", np.nan) for m in methods]\n",
    "    time = [row.get(f\"time_{m}\", np.nan) for m in methods]\n",
    "\n",
    "    ert_fmt = format_row(ert, mode=\"min\")\n",
    "    vol_fmt = format_row(vol, mode=\"min\")\n",
    "    wsc_fmt = format_row(wsc, mode=\"max\")\n",
    "    cov_fmt = format_row(cov, mode=None)\n",
    "    time_fmt = format_row(time, mode=\"min\")\n",
    "\n",
    "    # latex += f\"\\\\multirow{{3}}{{*}}{{\\\\rotatebox{{{90}}}{{{dataset}}}}} & ERT & \" + \" & \".join(ert_fmt) + \" \\\\\\\\\\n\"\n",
    "    latex += f\"\\\\multirow{{3}}{{*}}{{{{{dataset}}}}} & ERT [\\%] & \" + \" & \".join(ert_fmt) + \" \\\\\\\\\\n\"\n",
    "    latex += f\" & WSC & \" + \" & \".join(wsc_fmt) + \" \\\\\\\\\\n\"\n",
    "    # latex += f\" & Volume & \" + \" & \".join(vol_fmt) + \" \\\\\\\\\\n\"\n",
    "    # latex += f\" & Coverage & \" + \" & \".join(cov_fmt) + \" \\\\\\\\\\n\"\n",
    "    latex += f\" & Time [s] & \" + \" & \".join(time_fmt) + \" \\\\\\\\\\n\"\n",
    "    latex += \"\\\\hline\\n\"\n",
    "\n",
    "latex += \"\\\\end{tabular}\\n\"\n",
    "latex += \"}\\n\"\n",
    "latex += \"\\\\label{tab:results_alpha01}\\n\"\n",
    "latex += \"\\\\end{table}\\n\"\n",
    "\n",
    "print(latex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade3c2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[ht]\n",
      "\\centering\n",
      "\\small\n",
      "\\caption{Comparison of conditional coverage ($\\alpha=0.1$) for different conformal methods using the ERT metric (lower is better) and WSC (closer to $0.9$ is better); volume, marginal coverage and the running time to calibrate the predictions. Best values in bold, second best underlined. N/A indicates that the method failed to produce valid results for the corresponding dataset due to poor conditional density estimation leading to numerical issues in high dimensions. Experiments are repeated 10 times, and the index number is the standard error across those 10 experiments.}\n",
      "\\begin{tabular}{l l c c c c c }\n",
      "\\hline\n",
      "{\\begin{tabular}{c} Dataset \\\\ {\\small [output dim]} \\end{tabular}} & Metric & Mahalanobis & HPD & ECM & OT & MVCS \\\\\n",
      "\\hline\n",
      "\\multirow{5}{*}{{Bias [2]}} & ERT [\\%] & $\\mathbf{1.68_{0.45}}$ & $\\underline{2.00_{0.58}}$ & $3.72_{0.51}$ & $3.69_{0.44}$ & $3.05_{0.40}$ \\\\\n",
      " & WSC & $0.72_{0.01}$ & $0.72_{0.01}$ & $0.72_{0.01}$ & $\\mathbf{0.73_{0.01}}$ & $\\underline{0.72_{0.01}}$ \\\\\n",
      " & Volume & $\\mathbf{1.07_{0.02}}$ & $1.34_{0.03}$ & $1.11_{0.02}$ & $1.28_{0.04}$ & $\\underline{1.09_{0.02}}$ \\\\\n",
      " & Coverage & $0.90_{0.01}$ & $0.90_{0.01}$ & $0.90_{0.01}$ & $0.90_{0.01}$ & $0.90_{0.01}$ \\\\\n",
      " & Time [s] & $0.06_{0.02}$ & $556.89_{78.37}$ & $0.01_{0.00}$ & $19.91_{6.73}$ & $0.12_{0.03}$ \\\\\n",
      "\\hline\n",
      "\\multirow{5}{*}{{CASP [2]}} & ERT [\\%] & $\\underline{1.89_{0.25}}$ & $\\mathbf{1.52_{0.20}}$ & $4.64_{0.17}$ & $4.32_{0.18}$ & $2.31_{0.20}$ \\\\\n",
      " & WSC & $\\underline{0.82_{0.00}}$ & $\\mathbf{0.84_{0.00}}$ & $0.80_{0.01}$ & $0.80_{0.01}$ & $0.82_{0.01}$ \\\\\n",
      " & Volume & $1.37_{0.02}$ & $\\underline{1.32_{0.01}}$ & $1.57_{0.01}$ & $1.54_{0.02}$ & $\\mathbf{1.30_{0.01}}$ \\\\\n",
      " & Coverage & $0.90_{0.00}$ & $0.90_{0.00}$ & $0.90_{0.00}$ & $0.90_{0.00}$ & $0.90_{0.00}$ \\\\\n",
      " & Time [s] & $0.05_{0.00}$ & $2005.97_{47.81}$ & $0.02_{0.00}$ & $2.52_{0.34}$ & $0.45_{0.07}$ \\\\\n",
      "\\hline\n",
      "\\multirow{5}{*}{{House [2]}} & ERT [\\%] & $\\underline{3.01_{0.23}}$ & $\\mathbf{2.52_{0.30}}$ & $6.54_{0.36}$ & $6.56_{0.33}$ & $6.84_{0.41}$ \\\\\n",
      " & WSC & $\\underline{0.77_{0.01}}$ & $\\mathbf{0.80_{0.00}}$ & $0.72_{0.01}$ & $0.72_{0.01}$ & $0.71_{0.01}$ \\\\\n",
      " & Volume & $\\mathbf{1.00_{0.01}}$ & $1.15_{0.01}$ & $1.22_{0.01}$ & $1.25_{0.02}$ & $\\underline{1.15_{0.01}}$ \\\\\n",
      " & Coverage & $0.90_{0.00}$ & $0.90_{0.00}$ & $0.90_{0.00}$ & $0.90_{0.00}$ & $0.90_{0.00}$ \\\\\n",
      " & Time [s] & $0.04_{0.02}$ & $1549.27_{154.06}$ & $0.01_{0.00}$ & $0.48_{0.02}$ & $0.15_{0.01}$ \\\\\n",
      "\\hline\n",
      "\\multirow{5}{*}{{rf1 [8]}} & ERT [\\%] & $\\mathbf{3.02_{0.76}}$ & $4.70_{0.36}$ & $11.24_{0.37}$ & $\\underline{3.30_{0.56}}$ & $9.62_{0.36}$ \\\\\n",
      " & WSC & $\\underline{0.73_{0.01}}$ & $\\mathbf{0.74_{0.01}}$ & $0.53_{0.02}$ & $0.73_{0.01}$ & $0.55_{0.02}$ \\\\\n",
      " & Volume & $\\underline{0.28_{0.00}}$ & $0.46_{0.01}$ & $0.60_{0.01}$ & $0.53_{0.02}$ & $\\mathbf{0.28_{0.00}}$ \\\\\n",
      " & Coverage & $0.91_{0.00}$ & $0.91_{0.01}$ & $0.90_{0.00}$ & $0.90_{0.00}$ & $0.90_{0.00}$ \\\\\n",
      " & Time [s] & $0.04_{0.01}$ & $460.26_{5.79}$ & $0.01_{0.00}$ & $18.98_{3.74}$ & $0.14_{0.03}$ \\\\\n",
      "\\hline\n",
      "\\multirow{5}{*}{{rf2 [8]}} & ERT [\\%] & $\\mathbf{3.36_{0.77}}$ & $\\underline{4.73_{0.31}}$ & $9.92_{0.47}$ & $5.84_{0.32}$ & $8.37_{0.35}$ \\\\\n",
      " & WSC & $\\underline{0.73_{0.01}}$ & $0.73_{0.01}$ & $0.72_{0.01}$ & $\\mathbf{0.74_{0.01}}$ & $0.71_{0.01}$ \\\\\n",
      " & Volume & $\\mathbf{0.35_{0.02}}$ & $0.44_{0.00}$ & $0.67_{0.03}$ & $0.85_{0.02}$ & $\\underline{0.38_{0.02}}$ \\\\\n",
      " & Coverage & $0.90_{0.00}$ & $0.91_{0.01}$ & $0.90_{0.01}$ & $0.91_{0.01}$ & $0.90_{0.01}$ \\\\\n",
      " & Time [s] & $0.03_{0.00}$ & $636.24_{197.26}$ & $0.01_{0.00}$ & $35.04_{5.19}$ & $0.07_{0.00}$ \\\\\n",
      "\\hline\n",
      "\\multirow{5}{*}{{scm1d [16]}} & ERT [\\%] & $\\mathbf{3.01_{0.35}}$ & N/A & $12.33_{0.39}$ & $\\underline{3.60_{0.27}}$ & $11.43_{0.22}$ \\\\\n",
      " & WSC & $\\mathbf{0.73_{0.01}}$ & N/A & $0.57_{0.02}$ & $\\underline{0.73_{0.02}}$ & $0.57_{0.02}$ \\\\\n",
      " & Volume & $\\mathbf{1.14_{0.01}}$ & N/A & $1.51_{0.02}$ & $1.67_{0.03}$ & $\\underline{1.29_{0.01}}$ \\\\\n",
      " & Coverage & $0.89_{0.01}$ & N/A & $0.90_{0.01}$ & $0.89_{0.01}$ & $0.90_{0.00}$ \\\\\n",
      " & Time [s] & $0.05_{0.00}$ & N/A & $0.01_{0.00}$ & $22.68_{6.77}$ & $0.08_{0.01}$ \\\\\n",
      "\\hline\n",
      "\\multirow{5}{*}{{scm20d [16]}} & ERT [\\%] & $\\mathbf{1.39_{0.49}}$ & N/A & $9.29_{0.40}$ & $\\underline{2.91_{0.36}}$ & $8.99_{0.28}$ \\\\\n",
      " & WSC & $\\underline{0.74_{0.01}}$ & N/A & $0.70_{0.01}$ & $\\mathbf{0.75_{0.01}}$ & $0.70_{0.01}$ \\\\\n",
      " & Volume & $\\mathbf{1.29_{0.02}}$ & N/A & $1.75_{0.02}$ & $2.61_{0.08}$ & $\\underline{1.49_{0.02}}$ \\\\\n",
      " & Coverage & $0.90_{0.00}$ & N/A & $0.90_{0.00}$ & $0.91_{0.00}$ & $0.90_{0.00}$ \\\\\n",
      " & Time [s] & $0.16_{0.07}$ & N/A & $0.01_{0.00}$ & $27.74_{7.46}$ & $0.08_{0.01}$ \\\\\n",
      "\\hline\n",
      "\\multirow{5}{*}{{Taxi [2]}} & ERT [\\%] & $\\mathbf{0.64_{0.17}}$ & $\\underline{0.76_{0.14}}$ & $2.77_{0.12}$ & $3.68_{0.17}$ & $2.30_{0.13}$ \\\\\n",
      " & WSC & $\\underline{0.84_{0.00}}$ & $\\mathbf{0.85_{0.00}}$ & $0.80_{0.00}$ & $0.75_{0.01}$ & $0.82_{0.00}$ \\\\\n",
      " & Volume & $3.33_{0.01}$ & $\\mathbf{2.64_{0.13}}$ & $3.45_{0.01}$ & $3.34_{0.02}$ & $\\underline{3.32_{0.02}}$ \\\\\n",
      " & Coverage & $0.90_{0.00}$ & $0.90_{0.00}$ & $0.90_{0.00}$ & $0.90_{0.00}$ & $0.90_{0.00}$ \\\\\n",
      " & Time [s] & $0.06_{0.01}$ & $2596.51_{62.92}$ & $0.02_{0.00}$ & $4.67_{0.69}$ & $0.55_{0.11}$ \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\label{tab:app:results_alpha01}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "alpha = 0.1\n",
    "\n",
    "df = pd.read_csv(\"results_full.csv\")\n",
    "\n",
    "\n",
    "\n",
    "mask = df[\"coverage_HDR\"] == 1.0\n",
    "df.loc[mask, [\"coverage_HDR\", \"ERT_HDR\", \"WSC_HDR\", \"volume_HDR\", \"time_HDR\"]] = np.nan\n",
    "ert_cols = [c for c in df.columns if c.startswith(\"ERT_\")]\n",
    "df[ert_cols] = df[ert_cols] * 100\n",
    "\n",
    "cols = df.select_dtypes(include=np.number).columns\n",
    "mask = df.groupby([\"alpha\", \"dataset\"])[cols].transform(lambda s: s.isna().sum() >= 2)\n",
    "df[cols] = df[cols].mask(mask)\n",
    "\n",
    "methods = [\"levelset\", \"HDR\", \"one\", \"ot\", \"MVCS\"]\n",
    "\n",
    "# dataset name mapping\n",
    "dataset_map = {\n",
    "    \"biais\": \"Bias [2]\",\n",
    "    \"casp\": \"CASP [2]\",\n",
    "    \"house\": \"House [2]\",\n",
    "    \"rf1\": \"rf1 [8]\",\n",
    "    \"rf2\": \"rf2 [8]\",\n",
    "    \"scm1d\": \"scm1d [16]\",\n",
    "    \"scm20d\": \"scm20d [16]\",\n",
    "    \"taxi\": \"Taxi [2]\",\n",
    "}\n",
    "\n",
    "# method name mapping (for LaTeX header)\n",
    "method_map = {\n",
    "    \"levelset\": \"Mahalanobis\",\n",
    "    \"HDR\": \"HPD\",\n",
    "    \"one\": \"ECM\",\n",
    "    \"ot\": \"OT\",\n",
    "    \"MVCS\": \"MVCS\",\n",
    "}\n",
    "\n",
    "# keep alpha = 0.1 and compute means\n",
    "res = ( \n",
    "    df[df[\"alpha\"] == alpha] \n",
    "    .groupby(\"dataset\") \n",
    "    .agg([\"mean\", \"sem\"]) \n",
    ")\n",
    "\n",
    "def format_row_with_std(means, stds, mode=\"min\"):\n",
    "    \"\"\"\n",
    "    mode=\"min\": smallest bold, second smallest underlined\n",
    "    mode=\"max\": largest bold, second largest underlined\n",
    "    mode=None: no highlighting\n",
    "    \"\"\"\n",
    "    means = np.array(means, dtype=float)\n",
    "    stds = np.array(stds, dtype=float)\n",
    "\n",
    "    valid = ~np.isnan(means)\n",
    "\n",
    "    if mode == \"min\":\n",
    "        order = np.argsort(means)\n",
    "    elif mode == \"max\":\n",
    "        order = np.argsort(-means)\n",
    "    else:\n",
    "        order = []\n",
    "\n",
    "    best = order[0] if len(order) > 0 else None\n",
    "    second = order[1] if len(order) > 1 else None\n",
    "\n",
    "    out = []\n",
    "    for i, (m, s) in enumerate(zip(means, stds)):\n",
    "        if np.isnan(m):\n",
    "            out.append(\"N/A\")\n",
    "        else:\n",
    "            val = f\"{m:.2f}_{{{s:.2f}}}\"\n",
    "            if mode is not None:\n",
    "                if i == best:\n",
    "                    val = f\"\\\\mathbf{{{val}}}\"\n",
    "                elif i == second:\n",
    "                    val = f\"\\\\underline{{{val}}}\"\n",
    "            out.append(\"$\"+val+\"$\")\n",
    "    return out\n",
    "\n",
    "\n",
    "# ===== Build LaTeX table =====latex += f\"\\\\caption{{Comparison of methods for $\\\\alpha={alpha}$. Best values in bold, second best underlined.}}\\n\"\n",
    "\n",
    "\n",
    "header_methods = \" & \".join(method_map[m] for m in methods)\n",
    "\n",
    "latex = \"\"\n",
    "latex += \"\\\\begin{table}[ht]\\n\"\n",
    "latex += \"\\\\centering\\n\"\n",
    "latex += \"\\\\small\\n\"\n",
    "latex += f\"\\\\caption{{Comparison of conditional coverage ($\\\\alpha=0.1$) for different conformal methods using the ERT metric (lower is better) and WSC (closer to $0.9$ is better); volume, marginal coverage and the running time to calibrate the predictions. Best values in bold, second best underlined. N/A indicates that the method failed to produce valid results for the corresponding dataset due to poor conditional density estimation leading to numerical issues in high dimensions. Experiments are repeated 10 times, and the index number is the standard error across those 10 experiments.}}\\n\"\n",
    "latex += \"\\\\begin{tabular}{l l \" + \"c \" * len(methods) + \"}\\n\"\n",
    "latex += \"\\\\hline\\n\"\n",
    "latex += f\"{{\\\\begin{{tabular}}{{c}} Dataset \\\\\\\\ {{\\small [output dim]}} \\\\end{{tabular}}}} & Metric & {header_methods} \\\\\\\\\\n\"\n",
    "latex += \"\\\\hline\\n\"\n",
    "\n",
    "for dataset_raw, row in res.iterrows():\n",
    "    dataset = dataset_map.get(dataset_raw, dataset_raw)\n",
    "\n",
    "    def get_metric(metric, method):\n",
    "        return (\n",
    "            row[(f\"{metric}_{method}\", \"mean\")] if (f\"{metric}_{method}\", \"mean\") in row else np.nan,\n",
    "            row[(f\"{metric}_{method}\", \"sem\")] if (f\"{metric}_{method}\", \"sem\") in row else np.nan,\n",
    "        )\n",
    "\n",
    "    ert_mean, ert_std = zip(*[get_metric(\"ERT\", m) for m in methods])\n",
    "    vol_mean, vol_std = zip(*[get_metric(\"volume\", m) for m in methods])\n",
    "    wsc_mean, wsc_std = zip(*[get_metric(\"WSC\", m) for m in methods])\n",
    "    cov_mean, cov_std = zip(*[get_metric(\"coverage\", m) for m in methods])\n",
    "    time_mean, time_std = zip(*[get_metric(\"time\", m) for m in methods])\n",
    "\n",
    "    ert_fmt = format_row_with_std(ert_mean, ert_std, mode=\"min\")\n",
    "    vol_fmt = format_row_with_std(vol_mean, vol_std, mode=\"min\")\n",
    "    wsc_fmt = format_row_with_std(wsc_mean, wsc_std, mode=\"max\")\n",
    "    cov_fmt = format_row_with_std(cov_mean, cov_std, mode=None)\n",
    "    time_fmt = format_row_with_std(time_mean, time_std, mode=None)\n",
    "\n",
    "    \n",
    "    latex += f\"\\\\multirow{{5}}{{*}}{{{{{dataset}}}}} & ERT [\\%] & \" + \" & \".join(ert_fmt) + \" \\\\\\\\\\n\"\n",
    "    latex += f\" & WSC & \" + \" & \".join(wsc_fmt) + \" \\\\\\\\\\n\"\n",
    "    latex += f\" & Volume & \" + \" & \".join(vol_fmt) + \" \\\\\\\\\\n\"\n",
    "    latex += f\" & Coverage & \" + \" & \".join(cov_fmt) + \" \\\\\\\\\\n\"\n",
    "    latex += f\" & Time [s] & \" + \" & \".join(time_fmt) + \" \\\\\\\\\\n\"\n",
    "    latex += \"\\\\hline\\n\"\n",
    "\n",
    "latex += \"\\\\end{tabular}\\n\"\n",
    "latex += \"\\\\label{tab:app:results_alpha01}\\n\"\n",
    "latex += \"\\\\end{table}\\n\"\n",
    "\n",
    "print(latex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61125d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[ht]\n",
      "\\centering\n",
      "\\small\n",
      "\\caption{Comparison of conditional coverage ($\\alpha=0.05$) for different conformal methods using the ERT metric (lower is better) and WSC (closer to $0.95$ is better); volume, marginal coverage and the running time to calibrate the predictions. Best values in bold, second best underlined. N/A indicates that the method failed to produce valid results for the corresponding dataset due to poor conditional density estimation leading to numerical issues in high dimensions. Experiments are repeated 10 times, and the index number is the standard error across those 10 experiments.}\n",
      "\\begin{tabular}{l l c c c c c }\n",
      "\\hline\n",
      "{\\begin{tabular}{c} Dataset \\\\ {\\small [output dim]} \\end{tabular}} & Metric & Mahalanobis & HPD & ECM & OT & MVCS \\\\\n",
      "\\hline\n",
      "\\multirow{5}{*}{{Bias [2]}} & ERT [\\%] & $\\mathbf{1.26_{0.24}}$ & $1.61_{0.23}$ & $2.12_{0.20}$ & $1.82_{0.43}$ & $\\underline{1.28_{0.25}}$ \\\\\n",
      " & WSC & $0.72_{0.02}$ & $\\underline{0.76_{0.02}}$ & $0.75_{0.01}$ & $\\mathbf{0.76_{0.02}}$ & $0.73_{0.01}$ \\\\\n",
      " & Volume & $\\mathbf{1.29_{0.03}}$ & $1.68_{0.04}$ & $1.36_{0.04}$ & $1.47_{0.04}$ & $\\underline{1.31_{0.03}}$ \\\\\n",
      " & Coverage & $0.95_{0.00}$ & $0.96_{0.01}$ & $0.95_{0.00}$ & $0.96_{0.00}$ & $0.95_{0.00}$ \\\\\n",
      " & Time [s] & $0.02_{0.00}$ & $626.41_{116.25}$ & $0.01_{0.00}$ & $13.21_{3.27}$ & $0.11_{0.02}$ \\\\\n",
      "\\hline\n",
      "\\multirow{5}{*}{{CASP [2]}} & ERT [\\%] & $0.97_{0.14}$ & $\\underline{0.83_{0.17}}$ & $2.44_{0.11}$ & $2.03_{0.12}$ & $\\mathbf{0.80_{0.12}}$ \\\\\n",
      " & WSC & $0.86_{0.01}$ & $\\mathbf{0.87_{0.00}}$ & $0.85_{0.00}$ & $0.86_{0.00}$ & $\\underline{0.87_{0.00}}$ \\\\\n",
      " & Volume & $\\underline{1.73_{0.03}}$ & $1.74_{0.02}$ & $1.97_{0.02}$ & $2.31_{0.04}$ & $\\mathbf{1.63_{0.01}}$ \\\\\n",
      " & Coverage & $0.95_{0.00}$ & $0.95_{0.00}$ & $0.95_{0.00}$ & $0.95_{0.00}$ & $0.95_{0.00}$ \\\\\n",
      " & Time [s] & $0.03_{0.00}$ & $3108.31_{349.80}$ & $0.01_{0.00}$ & $2.49_{0.34}$ & $0.43_{0.07}$ \\\\\n",
      "\\hline\n",
      "\\multirow{5}{*}{{House [2]}} & ERT [\\%] & $\\underline{1.97_{0.24}}$ & $\\mathbf{1.20_{0.22}}$ & $3.68_{0.27}$ & $3.49_{0.17}$ & $3.50_{0.13}$ \\\\\n",
      " & WSC & $\\underline{0.81_{0.01}}$ & $\\mathbf{0.83_{0.01}}$ & $0.75_{0.01}$ & $0.75_{0.01}$ & $0.78_{0.01}$ \\\\\n",
      " & Volume & $\\mathbf{1.23_{0.02}}$ & $1.46_{0.02}$ & $1.61_{0.02}$ & $1.82_{0.05}$ & $\\underline{1.41_{0.04}}$ \\\\\n",
      " & Coverage & $0.95_{0.00}$ & $0.96_{0.00}$ & $0.95_{0.00}$ & $0.95_{0.00}$ & $0.95_{0.00}$ \\\\\n",
      " & Time [s] & $0.02_{0.00}$ & $1415.09_{307.96}$ & $0.01_{0.00}$ & $0.46_{0.02}$ & $0.15_{0.01}$ \\\\\n",
      "\\hline\n",
      "\\multirow{5}{*}{{rf1 [8]}} & ERT [\\%] & $\\mathbf{1.65_{0.30}}$ & N/A & $6.54_{0.21}$ & $\\underline{1.91_{0.21}}$ & $4.64_{0.27}$ \\\\\n",
      " & WSC & $\\mathbf{0.76_{0.01}}$ & N/A & $0.54_{0.02}$ & $\\underline{0.76_{0.02}}$ & $0.63_{0.03}$ \\\\\n",
      " & Volume & $\\underline{0.32_{0.00}}$ & N/A & $0.89_{0.02}$ & $0.55_{0.02}$ & $\\mathbf{0.31_{0.01}}$ \\\\\n",
      " & Coverage & $0.96_{0.00}$ & N/A & $0.95_{0.00}$ & $0.96_{0.00}$ & $0.95_{0.00}$ \\\\\n",
      " & Time [s] & $0.03_{0.00}$ & N/A & $0.01_{0.00}$ & $14.99_{3.40}$ & $0.13_{0.02}$ \\\\\n",
      "\\hline\n",
      "\\multirow{5}{*}{{rf2 [8]}} & ERT [\\%] & $\\mathbf{1.80_{0.47}}$ & N/A & $6.11_{0.26}$ & $\\underline{3.06_{0.25}}$ & $4.61_{0.39}$ \\\\\n",
      " & WSC & $\\underline{0.74_{0.01}}$ & N/A & $0.73_{0.01}$ & $\\mathbf{0.76_{0.01}}$ & $0.72_{0.01}$ \\\\\n",
      " & Volume & $\\mathbf{0.40_{0.02}}$ & N/A & $0.95_{0.02}$ & $0.87_{0.02}$ & $\\underline{0.42_{0.02}}$ \\\\\n",
      " & Coverage & $0.95_{0.00}$ & N/A & $0.95_{0.00}$ & $0.96_{0.00}$ & $0.95_{0.00}$ \\\\\n",
      " & Time [s] & $0.02_{0.00}$ & N/A & $0.01_{0.00}$ & $32.81_{4.79}$ & $0.07_{0.00}$ \\\\\n",
      "\\hline\n",
      "\\multirow{5}{*}{{scm1d [16]}} & ERT [\\%] & $\\mathbf{1.38_{0.26}}$ & N/A & $6.39_{0.19}$ & $\\underline{2.05_{0.43}}$ & $6.18_{0.19}$ \\\\\n",
      " & WSC & $\\underline{0.74_{0.01}}$ & N/A & $0.54_{0.01}$ & $\\mathbf{0.76_{0.03}}$ & $0.54_{0.02}$ \\\\\n",
      " & Volume & $\\mathbf{1.29_{0.01}}$ & N/A & $1.96_{0.04}$ & $1.69_{0.04}$ & $\\underline{1.65_{0.04}}$ \\\\\n",
      " & Coverage & $0.94_{0.00}$ & N/A & $0.95_{0.00}$ & $0.95_{0.01}$ & $0.95_{0.00}$ \\\\\n",
      " & Time [s] & $0.05_{0.01}$ & N/A & $0.01_{0.00}$ & $27.77_{7.05}$ & $0.08_{0.00}$ \\\\\n",
      "\\hline\n",
      "\\multirow{5}{*}{{scm20d [16]}} & ERT [\\%] & $\\mathbf{0.92_{0.30}}$ & N/A & $5.97_{0.20}$ & $\\underline{1.09_{0.28}}$ & $5.47_{0.22}$ \\\\\n",
      " & WSC & $\\underline{0.76_{0.01}}$ & N/A & $0.68_{0.01}$ & $\\mathbf{0.77_{0.01}}$ & $0.69_{0.01}$ \\\\\n",
      " & Volume & $\\mathbf{1.49_{0.02}}$ & N/A & $2.19_{0.04}$ & $2.64_{0.09}$ & $\\underline{1.87_{0.03}}$ \\\\\n",
      " & Coverage & $0.95_{0.00}$ & N/A & $0.95_{0.00}$ & $0.96_{0.00}$ & $0.95_{0.00}$ \\\\\n",
      " & Time [s] & $0.05_{0.01}$ & N/A & $0.01_{0.00}$ & $19.46_{4.58}$ & $0.10_{0.02}$ \\\\\n",
      "\\hline\n",
      "\\multirow{5}{*}{{Taxi [2]}} & ERT [\\%] & $\\mathbf{0.56_{0.14}}$ & $\\underline{0.64_{0.16}}$ & $1.80_{0.11}$ & $2.13_{0.15}$ & $1.80_{0.12}$ \\\\\n",
      " & WSC & $\\underline{0.88_{0.00}}$ & $\\mathbf{0.89_{0.00}}$ & $0.85_{0.00}$ & $0.82_{0.01}$ & $0.85_{0.00}$ \\\\\n",
      " & Volume & $4.07_{0.02}$ & $\\mathbf{3.24_{0.06}}$ & $4.19_{0.02}$ & $\\underline{3.95_{0.02}}$ & $4.08_{0.02}$ \\\\\n",
      " & Coverage & $0.95_{0.00}$ & $0.95_{0.00}$ & $0.95_{0.00}$ & $0.95_{0.00}$ & $0.95_{0.00}$ \\\\\n",
      " & Time [s] & $0.04_{0.00}$ & $2452.94_{63.99}$ & $0.02_{0.00}$ & $4.56_{0.67}$ & $0.55_{0.10}$ \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\label{tab:app:results_alpha005}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "df = pd.read_csv(\"results_full.csv\")\n",
    "\n",
    "\n",
    "\n",
    "mask = df[\"coverage_HDR\"] == 1.0\n",
    "df.loc[mask, [\"coverage_HDR\", \"ERT_HDR\", \"WSC_HDR\", \"volume_HDR\", \"time_HDR\"]] = np.nan\n",
    "ert_cols = [c for c in df.columns if c.startswith(\"ERT_\")]\n",
    "df[ert_cols] = df[ert_cols] * 100\n",
    "\n",
    "cols = df.select_dtypes(include=np.number).columns\n",
    "mask = df.groupby([\"alpha\", \"dataset\"])[cols].transform(lambda s: s.isna().sum() >= 2)\n",
    "df[cols] = df[cols].mask(mask)\n",
    "\n",
    "methods = [\"levelset\", \"HDR\", \"one\", \"ot\", \"MVCS\"]\n",
    "\n",
    "# dataset name mapping\n",
    "dataset_map = {\n",
    "    \"biais\": \"Bias [2]\",\n",
    "    \"casp\": \"CASP [2]\",\n",
    "    \"house\": \"House [2]\",\n",
    "    \"rf1\": \"rf1 [8]\",\n",
    "    \"rf2\": \"rf2 [8]\",\n",
    "    \"scm1d\": \"scm1d [16]\",\n",
    "    \"scm20d\": \"scm20d [16]\",\n",
    "    \"taxi\": \"Taxi [2]\",\n",
    "}\n",
    "\n",
    "# method name mapping (for LaTeX header)\n",
    "method_map = {\n",
    "    \"levelset\": \"Mahalanobis\",\n",
    "    \"HDR\": \"HPD\",\n",
    "    \"one\": \"ECM\",\n",
    "    \"ot\": \"OT\",\n",
    "    \"MVCS\": \"MVCS\",\n",
    "}\n",
    "\n",
    "# keep alpha = 0.1 and compute means\n",
    "res = ( \n",
    "    df[df[\"alpha\"] == alpha] \n",
    "    .groupby(\"dataset\") \n",
    "    .agg([\"mean\", \"sem\"]) \n",
    ")\n",
    "\n",
    "def format_row_with_std(means, stds, mode=\"min\"):\n",
    "    \"\"\"\n",
    "    mode=\"min\": smallest bold, second smallest underlined\n",
    "    mode=\"max\": largest bold, second largest underlined\n",
    "    mode=None: no highlighting\n",
    "    \"\"\"\n",
    "    means = np.array(means, dtype=float)\n",
    "    stds = np.array(stds, dtype=float)\n",
    "\n",
    "    valid = ~np.isnan(means)\n",
    "\n",
    "    if mode == \"min\":\n",
    "        order = np.argsort(means)\n",
    "    elif mode == \"max\":\n",
    "        order = np.argsort(-means)\n",
    "    else:\n",
    "        order = []\n",
    "\n",
    "    best = order[0] if len(order) > 0 else None\n",
    "    second = order[1] if len(order) > 1 else None\n",
    "\n",
    "    out = []\n",
    "    for i, (m, s) in enumerate(zip(means, stds)):\n",
    "        if np.isnan(m):\n",
    "            out.append(\"N/A\")\n",
    "        else:\n",
    "            val = f\"{m:.2f}_{{{s:.2f}}}\"\n",
    "            if mode is not None:\n",
    "                if i == best:\n",
    "                    val = f\"\\\\mathbf{{{val}}}\"\n",
    "                elif i == second:\n",
    "                    val = f\"\\\\underline{{{val}}}\"\n",
    "            out.append(\"$\"+val+\"$\")\n",
    "    return out\n",
    "\n",
    "\n",
    "# ===== Build LaTeX table =====latex += f\"\\\\caption{{Comparison of methods for $\\\\alpha={alpha}$. Best values in bold, second best underlined.}}\\n\"\n",
    "\n",
    "\n",
    "header_methods = \" & \".join(method_map[m] for m in methods)\n",
    "\n",
    "latex = \"\"\n",
    "latex += \"\\\\begin{table}[ht]\\n\"\n",
    "latex += \"\\\\centering\\n\"\n",
    "latex += \"\\\\small\\n\"\n",
    "latex += f\"\\\\caption{{Comparison of conditional coverage ($\\\\alpha=0.05$) for different conformal methods using the ERT metric (lower is better) and WSC (closer to $0.95$ is better); volume, marginal coverage and the running time to calibrate the predictions. Best values in bold, second best underlined. N/A indicates that the method failed to produce valid results for the corresponding dataset due to poor conditional density estimation leading to numerical issues in high dimensions. Experiments are repeated 10 times, and the index number is the standard error across those 10 experiments.}}\\n\"\n",
    "latex += \"\\\\begin{tabular}{l l \" + \"c \" * len(methods) + \"}\\n\"\n",
    "latex += \"\\\\hline\\n\"\n",
    "latex += f\"{{\\\\begin{{tabular}}{{c}} Dataset \\\\\\\\ {{\\small [output dim]}} \\\\end{{tabular}}}} & Metric & {header_methods} \\\\\\\\\\n\"\n",
    "latex += \"\\\\hline\\n\"\n",
    "\n",
    "for dataset_raw, row in res.iterrows():\n",
    "    dataset = dataset_map.get(dataset_raw, dataset_raw)\n",
    "\n",
    "    def get_metric(metric, method):\n",
    "        return (\n",
    "            row[(f\"{metric}_{method}\", \"mean\")] if (f\"{metric}_{method}\", \"mean\") in row else np.nan,\n",
    "            row[(f\"{metric}_{method}\", \"sem\")] if (f\"{metric}_{method}\", \"sem\") in row else np.nan,\n",
    "        )\n",
    "\n",
    "    ert_mean, ert_std = zip(*[get_metric(\"ERT\", m) for m in methods])\n",
    "    vol_mean, vol_std = zip(*[get_metric(\"volume\", m) for m in methods])\n",
    "    wsc_mean, wsc_std = zip(*[get_metric(\"WSC\", m) for m in methods])\n",
    "    cov_mean, cov_std = zip(*[get_metric(\"coverage\", m) for m in methods])\n",
    "    time_mean, time_std = zip(*[get_metric(\"time\", m) for m in methods])\n",
    "\n",
    "    ert_fmt = format_row_with_std(ert_mean, ert_std, mode=\"min\")\n",
    "    vol_fmt = format_row_with_std(vol_mean, vol_std, mode=\"min\")\n",
    "    wsc_fmt = format_row_with_std(wsc_mean, wsc_std, mode=\"max\")\n",
    "    cov_fmt = format_row_with_std(cov_mean, cov_std, mode=None)\n",
    "    time_fmt = format_row_with_std(time_mean, time_std, mode=None)\n",
    "\n",
    "    \n",
    "    latex += f\"\\\\multirow{{5}}{{*}}{{{{{dataset}}}}} & ERT [\\%] & \" + \" & \".join(ert_fmt) + \" \\\\\\\\\\n\"\n",
    "    latex += f\" & WSC & \" + \" & \".join(wsc_fmt) + \" \\\\\\\\\\n\"\n",
    "    latex += f\" & Volume & \" + \" & \".join(vol_fmt) + \" \\\\\\\\\\n\"\n",
    "    latex += f\" & Coverage & \" + \" & \".join(cov_fmt) + \" \\\\\\\\\\n\"\n",
    "    latex += f\" & Time [s] & \" + \" & \".join(time_fmt) + \" \\\\\\\\\\n\"\n",
    "    latex += \"\\\\hline\\n\"\n",
    "\n",
    "latex += \"\\\\end{tabular}\\n\"\n",
    "latex += \"\\\\label{tab:app:results_alpha005}\\n\"\n",
    "latex += \"\\\\end{table}\\n\"\n",
    "\n",
    "print(latex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2307fe0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd74e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[ht]\n",
      "\\centering\n",
      "\\small\n",
      "\\caption{Marginal coverage when conformalizing with missing outputs (desired coverage 0.9).}\n",
      "\\begin{tabular}{l|cc|cc}\n",
      "\\hline\n",
      "Dataset & \\multicolumn{2}{c|}{Missing at random} & \\multicolumn{2}{c}{10\\% extreme removed} \\\\ \n",
      " & With missing & Full output & With missing & Full output \\\\ \\hline\n",
      "Bias & $95.8 \\pm 0.6$ & $92.1 \\pm 0.9$ & $95.7 \\pm 0.7$ & $96.2 \\pm 0.6$ \\\\ \\hline\n",
      "CASP & $95.0 \\pm 0.4$ & $93.7 \\pm 0.7$ & $95.1 \\pm 0.4$ & $95.2 \\pm 0.4$ \\\\ \\hline\n",
      "House & $94.9 \\pm 0.8$ & $93.1 \\pm 1.1$ & $94.9 \\pm 0.9$ & $93.5 \\pm 1.0$ \\\\ \\hline\n",
      "rf1 & $95.6 \\pm 0.8$ & $93.4 \\pm 1.1$ & $95.6 \\pm 0.9$ & $94.6 \\pm 1.1$ \\\\ \\hline\n",
      "rf2 & $95.1 \\pm 0.8$ & $93.1 \\pm 1.1$ & $95.2 \\pm 1.1$ & $94.0 \\pm 1.4$ \\\\ \\hline\n",
      "scm1d & $94.8 \\pm 0.8$ & $89.0 \\pm 1.9$ & $94.8 \\pm 0.7$ & $93.2 \\pm 1.2$ \\\\ \\hline\n",
      "scm20d & $94.7 \\pm 0.7$ & $88.8 \\pm 1.7$ & $95.3 \\pm 1.5$ & $92.9 \\pm 1.3$ \\\\ \\hline\n",
      "Taxi & $95.0 \\pm 0.5$ & $93.8 \\pm 0.5$ & $94.9 \\pm 0.4$ & $88.9 \\pm 0.6$ \\\\ \\hline\n",
      "\\end{tabular}\n",
      "\\label{tab:coverage:missing:0.95}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load both datasets\n",
    "df_missing = pd.read_csv(\"results_missing.csv\")\n",
    "df_extreme = pd.read_csv(\"results_missing_extreme.csv\")\n",
    "\n",
    "# 2. Define a helper function to process dataframes identically\n",
    "def get_grouped_stats(df, alpha=0.05):\n",
    "    # Filter alpha\n",
    "    df_filtered = df[df[\"alpha\"] == alpha]\n",
    "    # Compute mean and std per dataset\n",
    "    return (\n",
    "        df_filtered.groupby(\"dataset\")[[\"coverage_nan\", \"coverage_full\"]]\n",
    "        .agg([\"mean\", \"std\"])\n",
    "    )\n",
    "\n",
    "# Calculate stats for both scenarios\n",
    "stats_missing = get_grouped_stats(df_missing)\n",
    "stats_extreme = get_grouped_stats(df_extreme)\n",
    "\n",
    "# 3. Define formatting function\n",
    "def fmt(mean, std):\n",
    "    # Formats as \"95.0 \\pm 1.2\"\n",
    "    return f\"${100*mean:.1f} \\\\pm {100*std:.1f}$\"\n",
    "\n",
    "name_map = {\n",
    "    \"biais\": \"Bias\",\n",
    "    \"casp\": \"CASP\",\n",
    "    \"house\": \"House\",\n",
    "    \"rf1\": \"rf1\",\n",
    "    \"rf2\": \"rf2\",\n",
    "    \"scm1d\": \"scm1d\",\n",
    "    \"scm20d\": \"scm20d\",\n",
    "    \"taxi\": \"Taxi\",\n",
    "}\n",
    "\n",
    "# 4. Construct the LaTeX Table\n",
    "latex = \"\"\n",
    "latex += \"\\\\begin{table}[ht]\\n\"\n",
    "latex += \"\\\\centering\\n\"\n",
    "latex += \"\\\\small\\n\"\n",
    "latex += \"\\\\caption{Marginal coverage when conformalizing with missing outputs (desired coverage 0.9).}\\n\"\n",
    "# {l|cc|cc} creates vertical lines between the Dataset and the two main groups\n",
    "latex += \"\\\\begin{tabular}{l|cc|cc}\\n\"\n",
    "latex += \"\\\\hline\\n\"\n",
    "\n",
    "# --- Header Row 1: The Main Groups ---\n",
    "# \\multicolumn{2}{c|}{...} spans 2 columns and adds a vertical line after\n",
    "latex += \"Dataset & \\\\multicolumn{2}{c|}{Missing at random} & \\\\multicolumn{2}{c}{10\\\\% extreme removed} \\\\\\\\ \\n\"\n",
    "\n",
    "# --- Header Row 2: The Sub-columns ---\n",
    "latex += \" & With missing & Full output & With missing & Full output \\\\\\\\ \\\\hline\\n\"\n",
    "\n",
    "# 5. Populate Rows\n",
    "# We iterate through the index of one stats object (assuming datasets match in both files)\n",
    "for dataset in stats_missing.index:\n",
    "    # Clean up name using the map\n",
    "    clean_name = name_map.get(dataset.lower(), dataset.capitalize())\n",
    "    \n",
    "    # Extract 'Missing at random' stats\n",
    "    m_nan = fmt(stats_missing.loc[dataset, (\"coverage_nan\", \"mean\")], \n",
    "                stats_missing.loc[dataset, (\"coverage_nan\", \"std\")])\n",
    "    m_full = fmt(stats_missing.loc[dataset, (\"coverage_full\", \"mean\")], \n",
    "                 stats_missing.loc[dataset, (\"coverage_full\", \"std\")])\n",
    "    \n",
    "    # Extract 'Extreme removed' stats\n",
    "    e_nan = fmt(stats_extreme.loc[dataset, (\"coverage_nan\", \"mean\")], \n",
    "                stats_extreme.loc[dataset, (\"coverage_nan\", \"std\")])\n",
    "    e_full = fmt(stats_extreme.loc[dataset, (\"coverage_full\", \"mean\")], \n",
    "                 stats_extreme.loc[dataset, (\"coverage_full\", \"std\")])\n",
    "\n",
    "    # Append row to LaTeX string\n",
    "    latex += f\"{clean_name} & {m_nan} & {m_full} & {e_nan} & {e_full} \\\\\\\\ \\\\hline\\n\"\n",
    "\n",
    "# 6. Close Table\n",
    "latex += \"\\\\end{tabular}\\n\"\n",
    "latex += \"\\\\label{tab:coverage:missing:0.95}\\n\"\n",
    "latex += \"\\\\end{table}\"\n",
    "\n",
    "print(latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d368f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08b3586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[ht]\n",
      "\\centering\n",
      "\\small\n",
      "\\caption{Comparison of conditional coverage ($\\alpha=0.1$) for partially reveled outputs for different conformal methods using the ERT metric (lower is better) and WSC (closer to $0.9$ is better); volume, marginal coverage and the running time to calibrate the predictions. Best values in bold, second best underlined. N/A indicates that the method failed to produce valid results for the corresponding dataset due to poor conditional density estimation leading to numerical issues in high dimensions. Experiments are repeated 10 times, and the index number is the standard error across those 10 experiments.}\n",
      "\\begin{tabular}{l l c c c c c }\n",
      "\\hline\n",
      "{\\begin{tabular}{c} Dataset \\\\ {\\small [output dim]} \\end{tabular}} & Metric & Mahalanobis & HPD & ECM & OT & MVCS \\\\\n",
      "\\hline\n",
      "\\multirow{5}{*}{{Bias [2]}} & ERT [\\%] & $\\mathbf{1.74_{0.32}}$ & $\\underline{1.98_{0.53}}$ & $4.03_{0.44}$ & $3.76_{0.37}$ & $3.31_{0.33}$ \\\\\n",
      " & WSC & $\\mathbf{0.73_{0.01}}$ & $0.72_{0.02}$ & $0.72_{0.01}$ & $0.72_{0.01}$ & $\\underline{0.73_{0.01}}$ \\\\\n",
      " & Volume & $\\mathbf{0.89_{0.02}}$ & $1.34_{0.03}$ & $\\underline{1.05_{0.03}}$ & $1.15_{0.04}$ & $1.05_{0.03}$ \\\\\n",
      " & Coverage & $0.90_{0.00}$ & $0.90_{0.01}$ & $0.90_{0.01}$ & $0.90_{0.01}$ & $0.90_{0.01}$ \\\\\n",
      " & Time [s] & $\\underline{0.02_{0.00}}$ & $556.89_{78.37}$ & $\\mathbf{0.01_{0.00}}$ & $19.91_{6.73}$ & $0.12_{0.03}$ \\\\\n",
      "\\hline\n",
      "\\multirow{5}{*}{{CASP [2]}} & ERT [\\%] & $\\mathbf{3.40_{0.35}}$ & $\\underline{4.76_{0.19}}$ & $9.31_{0.18}$ & $7.95_{0.21}$ & $5.37_{0.20}$ \\\\\n",
      " & WSC & $\\mathbf{0.80_{0.00}}$ & $\\underline{0.74_{0.01}}$ & $0.63_{0.01}$ & $0.71_{0.01}$ & $0.72_{0.01}$ \\\\\n",
      " & Volume & $\\mathbf{0.79_{0.01}}$ & $1.32_{0.01}$ & $1.20_{0.01}$ & $1.03_{0.20}$ & $\\underline{0.81_{0.01}}$ \\\\\n",
      " & Coverage & $0.90_{0.00}$ & $0.90_{0.00}$ & $0.90_{0.00}$ & $0.90_{0.00}$ & $0.90_{0.00}$ \\\\\n",
      " & Time [s] & $\\underline{0.04_{0.01}}$ & $2005.97_{47.81}$ & $\\mathbf{0.02_{0.00}}$ & $2.52_{0.34}$ & $0.45_{0.07}$ \\\\\n",
      "\\hline\n",
      "\\multirow{5}{*}{{House [2]}} & ERT [\\%] & $\\mathbf{2.77_{0.27}}$ & $\\underline{3.56_{0.17}}$ & $7.58_{0.29}$ & $7.09_{0.21}$ & $7.56_{0.36}$ \\\\\n",
      " & WSC & $\\underline{0.79_{0.01}}$ & $\\mathbf{0.80_{0.00}}$ & $0.72_{0.01}$ & $0.72_{0.01}$ & $0.72_{0.01}$ \\\\\n",
      " & Volume & $\\mathbf{0.74_{0.01}}$ & $1.15_{0.01}$ & $1.09_{0.02}$ & $1.34_{0.06}$ & $\\underline{0.98_{0.02}}$ \\\\\n",
      " & Coverage & $0.90_{0.00}$ & $0.90_{0.00}$ & $0.90_{0.00}$ & $0.90_{0.00}$ & $0.90_{0.00}$ \\\\\n",
      " & Time [s] & $\\underline{0.02_{0.00}}$ & $1549.27_{154.06}$ & $\\mathbf{0.01_{0.00}}$ & $0.48_{0.02}$ & $0.15_{0.01}$ \\\\\n",
      "\\hline\n",
      "\\multirow{5}{*}{{rf1 [8]}} & ERT [\\%] & $\\mathbf{3.37_{0.49}}$ & $4.92_{0.38}$ & $12.15_{0.35}$ & $\\underline{4.00_{0.56}}$ & $9.91_{0.39}$ \\\\\n",
      " & WSC & $0.72_{0.01}$ & $\\underline{0.73_{0.02}}$ & $0.53_{0.02}$ & $\\mathbf{0.73_{0.01}}$ & $0.55_{0.02}$ \\\\\n",
      " & Volume & $\\mathbf{0.26_{0.00}}$ & $0.46_{0.01}$ & $0.81_{0.01}$ & $0.55_{0.02}$ & $\\underline{0.30_{0.00}}$ \\\\\n",
      " & Coverage & $0.90_{0.00}$ & $0.91_{0.01}$ & $0.90_{0.00}$ & $0.90_{0.00}$ & $0.90_{0.00}$ \\\\\n",
      " & Time [s] & $\\underline{0.04_{0.01}}$ & $460.26_{5.79}$ & $\\mathbf{0.01_{0.00}}$ & $18.98_{3.74}$ & $0.14_{0.03}$ \\\\\n",
      "\\hline\n",
      "\\multirow{5}{*}{{rf2 [8]}} & ERT [\\%] & $\\mathbf{4.57_{0.29}}$ & $\\underline{4.96_{0.27}}$ & $11.03_{0.46}$ & $6.70_{0.43}$ & $8.68_{0.30}$ \\\\\n",
      " & WSC & $0.73_{0.01}$ & $\\underline{0.74_{0.01}}$ & $0.71_{0.01}$ & $\\mathbf{0.74_{0.01}}$ & $0.70_{0.01}$ \\\\\n",
      " & Volume & $\\mathbf{0.33_{0.01}}$ & $0.44_{0.00}$ & $0.90_{0.04}$ & $1.16_{0.06}$ & $\\underline{0.43_{0.03}}$ \\\\\n",
      " & Coverage & $0.90_{0.01}$ & $0.91_{0.01}$ & $0.90_{0.01}$ & $0.91_{0.01}$ & $0.90_{0.01}$ \\\\\n",
      " & Time [s] & $\\underline{0.03_{0.00}}$ & $636.24_{197.26}$ & $\\mathbf{0.01_{0.00}}$ & $35.04_{5.19}$ & $0.07_{0.00}$ \\\\\n",
      "\\hline\n",
      "\\multirow{5}{*}{{scm1d [16]}} & ERT [\\%] & $\\mathbf{2.99_{0.36}}$ & N/A & $12.38_{0.40}$ & $\\underline{3.71_{0.32}}$ & $11.65_{0.19}$ \\\\\n",
      " & WSC & $\\mathbf{0.73_{0.01}}$ & N/A & $0.58_{0.02}$ & $\\underline{0.73_{0.02}}$ & $0.58_{0.01}$ \\\\\n",
      " & Volume & $\\mathbf{1.12_{0.01}}$ & N/A & $1.58_{0.02}$ & $1.70_{0.03}$ & $\\underline{1.19_{0.02}}$ \\\\\n",
      " & Coverage & $0.90_{0.00}$ & N/A & $0.90_{0.01}$ & $0.89_{0.01}$ & $0.90_{0.00}$ \\\\\n",
      " & Time [s] & $\\underline{0.08_{0.00}}$ & N/A & $\\mathbf{0.01_{0.00}}$ & $22.68_{6.77}$ & $0.08_{0.01}$ \\\\\n",
      "\\hline\n",
      "\\multirow{5}{*}{{scm20d [16]}} & ERT [\\%] & $\\mathbf{1.73_{0.35}}$ & N/A & $11.20_{0.38}$ & $\\underline{4.75_{0.44}}$ & $10.30_{0.34}$ \\\\\n",
      " & WSC & $\\underline{0.74_{0.01}}$ & N/A & $0.66_{0.01}$ & $\\mathbf{0.75_{0.01}}$ & $0.67_{0.01}$ \\\\\n",
      " & Volume & $\\underline{1.24_{0.02}}$ & N/A & $1.80_{0.02}$ & $2.63_{0.08}$ & $\\mathbf{0.82_{0.04}}$ \\\\\n",
      " & Coverage & $0.90_{0.00}$ & N/A & $0.90_{0.00}$ & $0.91_{0.00}$ & $0.90_{0.00}$ \\\\\n",
      " & Time [s] & $\\underline{0.08_{0.01}}$ & N/A & $\\mathbf{0.01_{0.00}}$ & $27.74_{7.46}$ & $0.08_{0.01}$ \\\\\n",
      "\\hline\n",
      "\\multirow{5}{*}{{Taxi [2]}} & ERT [\\%] & $\\underline{9.36_{0.17}}$ & $\\mathbf{8.50_{0.19}}$ & $12.98_{0.15}$ & $11.65_{0.21}$ & $12.29_{0.19}$ \\\\\n",
      " & WSC & $\\underline{0.62_{0.01}}$ & $\\mathbf{0.66_{0.00}}$ & $0.51_{0.01}$ & $0.58_{0.01}$ & $0.51_{0.01}$ \\\\\n",
      " & Volume & $\\mathbf{2.61_{0.01}}$ & $\\underline{2.64_{0.13}}$ & $3.25_{0.01}$ & $2.67_{0.33}$ & $2.96_{0.02}$ \\\\\n",
      " & Coverage & $0.90_{0.00}$ & $0.90_{0.00}$ & $0.90_{0.00}$ & $0.90_{0.00}$ & $0.90_{0.00}$ \\\\\n",
      " & Time [s] & $\\underline{0.05_{0.01}}$ & $2596.51_{62.92}$ & $\\mathbf{0.02_{0.00}}$ & $4.67_{0.69}$ & $0.55_{0.11}$ \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\label{tab:app:results:revealed:alpha01}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "alpha = 0.1\n",
    "\n",
    "df = pd.read_csv(\"results_revealed.csv\")\n",
    "\n",
    "\n",
    "\n",
    "mask = df[\"coverage_HDR_known\"] == 1.0\n",
    "df.loc[mask, [\"coverage_HDR_known\", \"ERT_HDR_known\", \"WSC_HDR_known\", \"volume_HDR_known\", 'time_HDR_known']] = np.nan\n",
    "ert_cols = [c for c in df.columns if c.startswith(\"ERT_\")]\n",
    "df[ert_cols] = df[ert_cols] * 100\n",
    "\n",
    "cols = df.select_dtypes(include=np.number).columns\n",
    "mask = df.groupby([\"alpha\", \"dataset\"])[cols].transform(lambda s: s.isna().sum() >= 2)\n",
    "df[cols] = df[cols].mask(mask)\n",
    "\n",
    "methods = [\"with_bayes_levelset\", \"HDR_known\", \"one_covariance_known\", \"ot_known\", \"MVCS_known\"]\n",
    "\n",
    "# dataset name mapping\n",
    "dataset_map = {\n",
    "    \"biais\": \"Bias [2]\",\n",
    "    \"casp\": \"CASP [2]\",\n",
    "    \"house\": \"House [2]\",\n",
    "    \"rf1\": \"rf1 [8]\",\n",
    "    \"rf2\": \"rf2 [8]\",\n",
    "    \"scm1d\": \"scm1d [16]\",\n",
    "    \"scm20d\": \"scm20d [16]\",\n",
    "    \"taxi\": \"Taxi [2]\",\n",
    "}\n",
    "\n",
    "# method name mapping (for LaTeX header)\n",
    "method_map = {\n",
    "    \"with_bayes_levelset\": \"Mahalanobis\",\n",
    "    \"HDR_known\": \"HPD\",\n",
    "    \"one_covariance_known\": \"ECM\",\n",
    "    \"ot_known\": \"OT\",\n",
    "    \"MVCS_known\": \"MVCS\",\n",
    "}\n",
    "\n",
    "# keep alpha = 0.1 and compute means\n",
    "res = ( \n",
    "    df[df[\"alpha\"] == alpha] \n",
    "    .groupby(\"dataset\") \n",
    "    .agg([\"mean\", \"sem\"]) \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "def format_row_with_std(means, stds, mode=\"min\"):\n",
    "    \"\"\"\n",
    "    mode=\"min\": smallest bold, second smallest underlined\n",
    "    mode=\"max\": largest bold, second largest underlined\n",
    "    mode=None: no highlighting\n",
    "    \"\"\"\n",
    "    means = np.array(means, dtype=float)\n",
    "    stds = np.array(stds, dtype=float)\n",
    "\n",
    "    valid = ~np.isnan(means)\n",
    "\n",
    "    if mode == \"min\":\n",
    "        order = np.argsort(means)\n",
    "    elif mode == \"max\":\n",
    "        order = np.argsort(-means)\n",
    "    else:\n",
    "        order = []\n",
    "\n",
    "    best = order[0] if len(order) > 0 else None\n",
    "    second = order[1] if len(order) > 1 else None\n",
    "\n",
    "    out = []\n",
    "    for i, (m, s) in enumerate(zip(means, stds)):\n",
    "        if np.isnan(m):\n",
    "            out.append(\"N/A\")\n",
    "        else:\n",
    "            val = f\"{m:.2f}_{{{s:.2f}}}\"\n",
    "            if mode is not None:\n",
    "                if i == best:\n",
    "                    val = f\"\\\\mathbf{{{val}}}\"\n",
    "                elif i == second:\n",
    "                    val = f\"\\\\underline{{{val}}}\"\n",
    "            out.append(\"$\"+val+\"$\")\n",
    "    return out\n",
    "\n",
    "\n",
    "# ===== Build LaTeX table =====latex += f\"\\\\caption{{Comparison of methods for $\\\\alpha={alpha}$. Best values in bold, second best underlined.}}\\n\"\n",
    "\n",
    "\n",
    "header_methods = \" & \".join(method_map[m] for m in methods)\n",
    "\n",
    "latex = \"\"\n",
    "latex += \"\\\\begin{table}[ht]\\n\"\n",
    "latex += \"\\\\centering\\n\"\n",
    "latex += \"\\\\small\\n\"\n",
    "latex += f\"\\\\caption{{Comparison of conditional coverage ($\\\\alpha=0.1$) for partially reveled outputs for different conformal methods using the ERT metric (lower is better) and WSC (closer to $0.9$ is better); volume, marginal coverage and the running time to calibrate the predictions. Best values in bold, second best underlined. N/A indicates that the method failed to produce valid results for the corresponding dataset due to poor conditional density estimation leading to numerical issues in high dimensions. Experiments are repeated 10 times, and the index number is the standard error across those 10 experiments.}}\\n\"\n",
    "latex += \"\\\\begin{tabular}{l l \" + \"c \" * len(methods) + \"}\\n\"\n",
    "latex += \"\\\\hline\\n\"\n",
    "latex += f\"{{\\\\begin{{tabular}}{{c}} Dataset \\\\\\\\ {{\\small [output dim]}} \\\\end{{tabular}}}} & Metric & {header_methods} \\\\\\\\\\n\"\n",
    "latex += \"\\\\hline\\n\"\n",
    "\n",
    "for dataset_raw, row in res.iterrows():\n",
    "    dataset = dataset_map.get(dataset_raw, dataset_raw)\n",
    "\n",
    "    \n",
    "\n",
    "    def get_metric(metric, method):\n",
    "        \n",
    "        return (\n",
    "            row[(f\"{metric}_{method}\", \"mean\")] if (f\"{metric}_{method}\", \"mean\") in row else np.nan,\n",
    "            row[(f\"{metric}_{method}\", \"sem\")] if (f\"{metric}_{method}\", \"sem\") in row else np.nan,\n",
    "        )\n",
    "\n",
    "    ert_mean, ert_std = zip(*[get_metric(\"ERT\", m) for m in methods])\n",
    "    vol_mean, vol_std = zip(*[get_metric(\"volume\", m) for m in methods])\n",
    "    wsc_mean, wsc_std = zip(*[get_metric(\"WSC\", m) for m in methods])\n",
    "    cov_mean, cov_std = zip(*[get_metric(\"coverage\", m) for m in methods])\n",
    "    time_mean, time_std = zip(*[get_metric(\"time\", m) for m in methods])\n",
    "\n",
    "    ert_fmt = format_row_with_std(ert_mean, ert_std, mode=\"min\")\n",
    "    vol_fmt = format_row_with_std(vol_mean, vol_std, mode=\"min\")\n",
    "    wsc_fmt = format_row_with_std(wsc_mean, wsc_std, mode=\"max\")\n",
    "    cov_fmt = format_row_with_std(cov_mean, cov_std, mode=None)\n",
    "    time_fmt = format_row_with_std(time_mean, time_std, mode=\"min\")\n",
    "\n",
    "    \n",
    "    latex += f\"\\\\multirow{{5}}{{*}}{{{{{dataset}}}}} & ERT [\\%] & \" + \" & \".join(ert_fmt) + \" \\\\\\\\\\n\"\n",
    "    latex += f\" & WSC & \" + \" & \".join(wsc_fmt) + \" \\\\\\\\\\n\"\n",
    "    latex += f\" & Volume & \" + \" & \".join(vol_fmt) + \" \\\\\\\\\\n\"\n",
    "    latex += f\" & Coverage & \" + \" & \".join(cov_fmt) + \" \\\\\\\\\\n\"\n",
    "    latex += f\" & Time [s] & \" + \" & \".join(time_fmt) + \" \\\\\\\\\\n\"\n",
    "    latex += \"\\\\hline\\n\"\n",
    "\n",
    "latex += \"\\\\end{tabular}\\n\"\n",
    "latex += \"\\\\label{tab:app:results:revealed:alpha01}\\n\"\n",
    "latex += \"\\\\end{table}\\n\"\n",
    "\n",
    "print(latex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bded7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[ht]\n",
      "\\centering\n",
      "\\small\n",
      "\\caption{Comparison of conditional coverage ($\\alpha=0.05$) for partially reveled outputs for different conformal methods using the ERT metric (lower is better) and WSC (closer to $0.95$ is better); volume, marginal coverage and the running time to calibrate the predictions. Best values in bold, second best underlined. N/A indicates that the method failed to produce valid results for the corresponding dataset due to poor conditional density estimation leading to numerical issues in high dimensions Experiments are repeated 10 times, and the index number is the standard error across those 10 experiments.}\n",
      "\\begin{tabular}{l l c c c c c }\n",
      "\\hline\n",
      "{\\begin{tabular}{c} Dataset \\\\ {\\small [output dim]} \\end{tabular}} & Metric & Mahalanobis & HPD & ECM & OT & MVCS \\\\\n",
      "\\hline\n",
      "\\multirow{4}{*}{{Bias [2]}} & ERT [\\%] & $\\mathbf{1.30_{0.22}}$ & $1.67_{0.23}$ & $2.25_{0.20}$ & $2.14_{0.34}$ & $\\underline{1.54_{0.22}}$ \\\\\n",
      " & WSC & $0.75_{0.01}$ & $\\mathbf{0.76_{0.02}}$ & $0.75_{0.01}$ & $\\underline{0.76_{0.02}}$ & $0.74_{0.01}$ \\\\\n",
      " & Volume & $\\mathbf{1.10_{0.02}}$ & $1.68_{0.04}$ & $1.33_{0.04}$ & $1.34_{0.05}$ & $\\underline{1.30_{0.04}}$ \\\\\n",
      " & Coverage & $0.95_{0.00}$ & $0.96_{0.01}$ & $0.95_{0.00}$ & $0.96_{0.00}$ & $0.95_{0.00}$ \\\\\n",
      " & Time [s] & $\\underline{0.02_{0.00}}$ & $626.41_{116.25}$ & $\\mathbf{0.01_{0.00}}$ & $13.21_{3.27}$ & $0.11_{0.02}$ \\\\\n",
      "\\hline\n",
      "\\multirow{4}{*}{{CASP [2]}} & ERT [\\%] & $\\mathbf{1.27_{0.14}}$ & $\\underline{2.16_{0.12}}$ & $4.86_{0.15}$ & $4.24_{0.13}$ & $2.31_{0.12}$ \\\\\n",
      " & WSC & $\\mathbf{0.87_{0.00}}$ & $\\underline{0.82_{0.01}}$ & $0.65_{0.01}$ & $0.75_{0.01}$ & $0.78_{0.01}$ \\\\\n",
      " & Volume & $\\mathbf{1.12_{0.01}}$ & $1.74_{0.02}$ & $1.60_{0.01}$ & $2.30_{0.48}$ & $\\underline{1.12_{0.01}}$ \\\\\n",
      " & Coverage & $0.95_{0.00}$ & $0.95_{0.00}$ & $0.95_{0.00}$ & $0.95_{0.00}$ & $0.95_{0.00}$ \\\\\n",
      " & Time [s] & $\\underline{0.04_{0.00}}$ & $3108.31_{349.80}$ & $\\mathbf{0.01_{0.00}}$ & $2.49_{0.34}$ & $0.43_{0.07}$ \\\\\n",
      "\\hline\n",
      "\\multirow{4}{*}{{House [2]}} & ERT [\\%] & $\\mathbf{1.80_{0.21}}$ & $\\underline{1.89_{0.20}}$ & $4.18_{0.22}$ & $3.78_{0.16}$ & $3.80_{0.11}$ \\\\\n",
      " & WSC & $\\underline{0.83_{0.01}}$ & $\\mathbf{0.83_{0.01}}$ & $0.75_{0.01}$ & $0.75_{0.01}$ & $0.78_{0.01}$ \\\\\n",
      " & Volume & $\\mathbf{0.93_{0.01}}$ & $1.46_{0.02}$ & $1.52_{0.03}$ & $2.34_{0.12}$ & $\\underline{1.26_{0.05}}$ \\\\\n",
      " & Coverage & $0.95_{0.00}$ & $0.96_{0.00}$ & $0.95_{0.00}$ & $0.95_{0.00}$ & $0.95_{0.00}$ \\\\\n",
      " & Time [s] & $\\underline{0.02_{0.00}}$ & $1415.09_{307.96}$ & $\\mathbf{0.01_{0.00}}$ & $0.46_{0.02}$ & $0.15_{0.01}$ \\\\\n",
      "\\hline\n",
      "\\multirow{4}{*}{{rf1 [8]}} & ERT [\\%] & $\\mathbf{1.82_{0.15}}$ & N/A & $6.86_{0.22}$ & $\\underline{1.95_{0.21}}$ & $4.68_{0.24}$ \\\\\n",
      " & WSC & $\\mathbf{0.75_{0.01}}$ & N/A & $0.53_{0.03}$ & $\\underline{0.75_{0.02}}$ & $0.63_{0.03}$ \\\\\n",
      " & Volume & $\\mathbf{0.31_{0.01}}$ & N/A & $1.32_{0.03}$ & $0.56_{0.02}$ & $\\underline{0.36_{0.01}}$ \\\\\n",
      " & Coverage & $0.95_{0.00}$ & N/A & $0.95_{0.00}$ & $0.96_{0.00}$ & $0.95_{0.00}$ \\\\\n",
      " & Time [s] & $\\underline{0.04_{0.01}}$ & N/A & $\\mathbf{0.01_{0.00}}$ & $14.99_{3.40}$ & $0.13_{0.02}$ \\\\\n",
      "\\hline\n",
      "\\multirow{4}{*}{{rf2 [8]}} & ERT [\\%] & $\\mathbf{2.14_{0.39}}$ & N/A & $6.35_{0.29}$ & $\\underline{3.25_{0.33}}$ & $4.59_{0.38}$ \\\\\n",
      " & WSC & $\\underline{0.72_{0.01}}$ & N/A & $0.72_{0.01}$ & $\\mathbf{0.76_{0.02}}$ & $0.71_{0.02}$ \\\\\n",
      " & Volume & $\\mathbf{0.39_{0.02}}$ & N/A & $1.39_{0.03}$ & $1.19_{0.06}$ & $\\underline{0.51_{0.02}}$ \\\\\n",
      " & Coverage & $0.95_{0.00}$ & N/A & $0.95_{0.00}$ & $0.96_{0.00}$ & $0.95_{0.00}$ \\\\\n",
      " & Time [s] & $\\underline{0.03_{0.00}}$ & N/A & $\\mathbf{0.01_{0.00}}$ & $32.81_{4.79}$ & $0.07_{0.00}$ \\\\\n",
      "\\hline\n",
      "\\multirow{4}{*}{{scm1d [16]}} & ERT [\\%] & $\\mathbf{1.53_{0.21}}$ & N/A & $6.42_{0.20}$ & $\\underline{2.15_{0.35}}$ & $6.32_{0.22}$ \\\\\n",
      " & WSC & $\\underline{0.75_{0.01}}$ & N/A & $0.54_{0.02}$ & $\\mathbf{0.76_{0.03}}$ & $0.55_{0.02}$ \\\\\n",
      " & Volume & $\\mathbf{1.27_{0.01}}$ & N/A & $2.12_{0.04}$ & $1.72_{0.03}$ & $\\underline{1.69_{0.04}}$ \\\\\n",
      " & Coverage & $0.95_{0.00}$ & N/A & $0.95_{0.00}$ & $0.95_{0.01}$ & $0.95_{0.00}$ \\\\\n",
      " & Time [s] & $0.08_{0.01}$ & N/A & $\\mathbf{0.01_{0.00}}$ & $27.77_{7.05}$ & $\\underline{0.08_{0.00}}$ \\\\\n",
      "\\hline\n",
      "\\multirow{4}{*}{{scm20d [16]}} & ERT [\\%] & $\\mathbf{1.16_{0.24}}$ & N/A & $6.49_{0.25}$ & $\\underline{1.84_{0.21}}$ & $5.84_{0.30}$ \\\\\n",
      " & WSC & $\\underline{0.76_{0.01}}$ & N/A & $0.67_{0.01}$ & $\\mathbf{0.76_{0.01}}$ & $0.70_{0.01}$ \\\\\n",
      " & Volume & $\\underline{1.44_{0.02}}$ & N/A & $2.33_{0.05}$ & $2.66_{0.08}$ & $\\mathbf{1.22_{0.06}}$ \\\\\n",
      " & Coverage & $0.95_{0.00}$ & N/A & $0.95_{0.00}$ & $0.96_{0.00}$ & $0.95_{0.00}$ \\\\\n",
      " & Time [s] & $\\underline{0.08_{0.01}}$ & N/A & $\\mathbf{0.01_{0.00}}$ & $19.46_{4.58}$ & $0.10_{0.02}$ \\\\\n",
      "\\hline\n",
      "\\multirow{4}{*}{{Taxi [2]}} & ERT [\\%] & $\\underline{5.29_{0.12}}$ & $\\mathbf{4.26_{0.10}}$ & $7.11_{0.07}$ & $6.58_{0.11}$ & $6.89_{0.08}$ \\\\\n",
      " & WSC & $\\underline{0.71_{0.01}}$ & $\\mathbf{0.74_{0.01}}$ & $0.53_{0.01}$ & $0.63_{0.01}$ & $0.53_{0.01}$ \\\\\n",
      " & Volume & $\\underline{3.36_{0.01}}$ & $\\mathbf{3.24_{0.06}}$ & $4.14_{0.02}$ & $3.45_{0.37}$ & $3.93_{0.03}$ \\\\\n",
      " & Coverage & $0.95_{0.00}$ & $0.95_{0.00}$ & $0.95_{0.00}$ & $0.95_{0.00}$ & $0.95_{0.00}$ \\\\\n",
      " & Time [s] & $\\underline{0.05_{0.01}}$ & $2452.94_{63.99}$ & $\\mathbf{0.02_{0.00}}$ & $4.56_{0.67}$ & $0.55_{0.10}$ \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\label{tab:app:results:revealed:alpha005}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "df = pd.read_csv(\"results_revealed.csv\")\n",
    "\n",
    "\n",
    "\n",
    "mask = df[\"coverage_HDR_known\"] == 1.0\n",
    "df.loc[mask, [\"coverage_HDR_known\", \"ERT_HDR_known\", \"WSC_HDR_known\", \"volume_HDR_known\", 'time_HDR_known']] = np.nan\n",
    "ert_cols = [c for c in df.columns if c.startswith(\"ERT_\")]\n",
    "df[ert_cols] = df[ert_cols] * 100\n",
    "\n",
    "cols = df.select_dtypes(include=np.number).columns\n",
    "mask = df.groupby([\"alpha\", \"dataset\"])[cols].transform(lambda s: s.isna().sum() >= 2)\n",
    "df[cols] = df[cols].mask(mask)\n",
    "\n",
    "methods = [\"with_bayes_levelset\", \"HDR_known\", \"one_covariance_known\", \"ot_known\", \"MVCS_known\"]\n",
    "\n",
    "# dataset name mapping\n",
    "dataset_map = {\n",
    "    \"biais\": \"Bias [2]\",\n",
    "    \"casp\": \"CASP [2]\",\n",
    "    \"house\": \"House [2]\",\n",
    "    \"rf1\": \"rf1 [8]\",\n",
    "    \"rf2\": \"rf2 [8]\",\n",
    "    \"scm1d\": \"scm1d [16]\",\n",
    "    \"scm20d\": \"scm20d [16]\",\n",
    "    \"taxi\": \"Taxi [2]\",\n",
    "}\n",
    "\n",
    "# method name mapping (for LaTeX header)\n",
    "method_map = {\n",
    "    \"with_bayes_levelset\": \"Mahalanobis\",\n",
    "    \"HDR_known\": \"HPD\",\n",
    "    \"one_covariance_known\": \"ECM\",\n",
    "    \"ot_known\": \"OT\",\n",
    "    \"MVCS_known\": \"MVCS\",\n",
    "}\n",
    "\n",
    "# keep alpha = 0.1 and compute means\n",
    "res = ( \n",
    "    df[df[\"alpha\"] == alpha] \n",
    "    .groupby(\"dataset\") \n",
    "    .agg([\"mean\", \"sem\"]) \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "def format_row_with_std(means, stds, mode=\"min\"):\n",
    "    \"\"\"\n",
    "    mode=\"min\": smallest bold, second smallest underlined\n",
    "    mode=\"max\": largest bold, second largest underlined\n",
    "    mode=None: no highlighting\n",
    "    \"\"\"\n",
    "    means = np.array(means, dtype=float)\n",
    "    stds = np.array(stds, dtype=float)\n",
    "\n",
    "    valid = ~np.isnan(means)\n",
    "\n",
    "    if mode == \"min\":\n",
    "        order = np.argsort(means)\n",
    "    elif mode == \"max\":\n",
    "        order = np.argsort(-means)\n",
    "    else:\n",
    "        order = []\n",
    "\n",
    "    best = order[0] if len(order) > 0 else None\n",
    "    second = order[1] if len(order) > 1 else None\n",
    "\n",
    "    out = []\n",
    "    for i, (m, s) in enumerate(zip(means, stds)):\n",
    "        if np.isnan(m):\n",
    "            out.append(\"N/A\")\n",
    "        else:\n",
    "            val = f\"{m:.2f}_{{{s:.2f}}}\"\n",
    "            if mode is not None:\n",
    "                if i == best:\n",
    "                    val = f\"\\\\mathbf{{{val}}}\"\n",
    "                elif i == second:\n",
    "                    val = f\"\\\\underline{{{val}}}\"\n",
    "            out.append(\"$\"+val+\"$\")\n",
    "    return out\n",
    "\n",
    "\n",
    "# ===== Build LaTeX table =====latex += f\"\\\\caption{{Comparison of methods for $\\\\alpha={alpha}$. Best values in bold, second best underlined.}}\\n\"\n",
    "\n",
    "\n",
    "header_methods = \" & \".join(method_map[m] for m in methods)\n",
    "\n",
    "latex = \"\"\n",
    "latex += \"\\\\begin{table}[ht]\\n\"\n",
    "latex += \"\\\\centering\\n\"\n",
    "latex += \"\\\\small\\n\"\n",
    "latex += f\"\\\\caption{{Comparison of conditional coverage ($\\\\alpha=0.05$) for partially reveled outputs for different conformal methods using the ERT metric (lower is better) and WSC (closer to $0.95$ is better); volume, marginal coverage and the running time to calibrate the predictions. Best values in bold, second best underlined. N/A indicates that the method failed to produce valid results for the corresponding dataset due to poor conditional density estimation leading to numerical issues in high dimensions Experiments are repeated 10 times, and the index number is the standard error across those 10 experiments.}}\\n\"\n",
    "latex += \"\\\\begin{tabular}{l l \" + \"c \" * len(methods) + \"}\\n\"\n",
    "latex += \"\\\\hline\\n\"\n",
    "latex += f\"{{\\\\begin{{tabular}}{{c}} Dataset \\\\\\\\ {{\\small [output dim]}} \\\\end{{tabular}}}} & Metric & {header_methods} \\\\\\\\\\n\"\n",
    "latex += \"\\\\hline\\n\"\n",
    "\n",
    "for dataset_raw, row in res.iterrows():\n",
    "    dataset = dataset_map.get(dataset_raw, dataset_raw)\n",
    "\n",
    "    \n",
    "\n",
    "    def get_metric(metric, method):\n",
    "        \n",
    "        return (\n",
    "            row[(f\"{metric}_{method}\", \"mean\")] if (f\"{metric}_{method}\", \"mean\") in row else np.nan,\n",
    "            row[(f\"{metric}_{method}\", \"sem\")] if (f\"{metric}_{method}\", \"sem\") in row else np.nan,\n",
    "        )\n",
    "\n",
    "    ert_mean, ert_std = zip(*[get_metric(\"ERT\", m) for m in methods])\n",
    "    vol_mean, vol_std = zip(*[get_metric(\"volume\", m) for m in methods])\n",
    "    wsc_mean, wsc_std = zip(*[get_metric(\"WSC\", m) for m in methods])\n",
    "    cov_mean, cov_std = zip(*[get_metric(\"coverage\", m) for m in methods])\n",
    "    time_mean, time_std = zip(*[get_metric(\"time\", m) for m in methods])\n",
    "\n",
    "    ert_fmt = format_row_with_std(ert_mean, ert_std, mode=\"min\")\n",
    "    vol_fmt = format_row_with_std(vol_mean, vol_std, mode=\"min\")\n",
    "    wsc_fmt = format_row_with_std(wsc_mean, wsc_std, mode=\"max\")\n",
    "    cov_fmt = format_row_with_std(cov_mean, cov_std, mode=None)\n",
    "    time_fmt = format_row_with_std(time_mean, time_std, mode=\"min\")\n",
    "\n",
    "    \n",
    "    latex += f\"\\\\multirow{{4}}{{*}}{{{{{dataset}}}}} & ERT [\\%] & \" + \" & \".join(ert_fmt) + \" \\\\\\\\\\n\"\n",
    "    latex += f\" & WSC & \" + \" & \".join(wsc_fmt) + \" \\\\\\\\\\n\"\n",
    "    latex += f\" & Volume & \" + \" & \".join(vol_fmt) + \" \\\\\\\\\\n\"\n",
    "    latex += f\" & Coverage & \" + \" & \".join(cov_fmt) + \" \\\\\\\\\\n\"\n",
    "    latex += f\" & Time [s] & \" + \" & \".join(time_fmt) + \" \\\\\\\\\\n\"\n",
    "    latex += \"\\\\hline\\n\"\n",
    "\n",
    "latex += \"\\\\end{tabular}\\n\"\n",
    "latex += \"\\\\label{tab:app:results:revealed:alpha005}\\n\"\n",
    "latex += \"\\\\end{table}\\n\"\n",
    "\n",
    "print(latex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2ac50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[ht]\n",
      "\\centering\n",
      "\\small\n",
      "\\caption{Comparison of conditional coverage ($\\alpha=0.1$) for a projection of the outputs for different conformal methods using the ERT metric (lower is better) and WSC (closer to $0.9$ is better). Best values in bold, second best underlined. N/A indicates that the method failed to produce valid results for the corresponding dataset due to poor conditional density estimation leading to numerical issues in high dimensions Experiments are repeated 10 times, and the index number is the standard error across those 10 experiments.}\n",
      "\\begin{tabular}{l l c c c }\n",
      "\\hline\n",
      "Dataset & Metric & Mahalanobis & ECM & OT \\\\\n",
      "\\hline\n",
      "\\multirow{4}{*}{{Bias}} & ERT [\\%] & $\\mathbf{2.62_{0.39}}$ & $4.70_{0.49}$ & $\\underline{3.64_{0.50}}$ \\\\\n",
      " & WSC & $\\mathbf{0.73_{0.01}}$ & $0.72_{0.01}$ & $\\underline{0.73_{0.01}}$ \\\\\n",
      " & Volume & $\\mathbf{1.34_{0.15}}$ & $\\underline{1.52_{0.16}}$ & $2.00_{0.22}$ \\\\\n",
      " & Coverage & $0.90_{0.01}$ & $0.90_{0.01}$ & $0.90_{0.01}$ \\\\\n",
      "\\hline\n",
      "\\multirow{4}{*}{{CASP}} & ERT [\\%] & $\\mathbf{2.04_{0.28}}$ & $5.03_{0.16}$ & $\\underline{4.80_{0.25}}$ \\\\\n",
      " & WSC & $\\mathbf{0.82_{0.00}}$ & $\\underline{0.79_{0.01}}$ & $0.78_{0.01}$ \\\\\n",
      " & Volume & $\\mathbf{1.90_{0.23}}$ & $\\underline{2.16_{0.26}}$ & $2.18_{0.27}$ \\\\\n",
      " & Coverage & $0.90_{0.00}$ & $0.90_{0.00}$ & $0.90_{0.00}$ \\\\\n",
      "\\hline\n",
      "\\multirow{4}{*}{{House}} & ERT [\\%] & $\\mathbf{2.99_{0.31}}$ & $7.87_{0.37}$ & $\\underline{7.59_{0.32}}$ \\\\\n",
      " & WSC & $\\mathbf{0.77_{0.00}}$ & $0.73_{0.01}$ & $\\underline{0.74_{0.01}}$ \\\\\n",
      " & Volume & $\\mathbf{1.92_{0.17}}$ & $\\underline{2.59_{0.24}}$ & $2.64_{0.25}$ \\\\\n",
      " & Coverage & $0.90_{0.00}$ & $0.90_{0.00}$ & $0.90_{0.00}$ \\\\\n",
      "\\hline\n",
      "\\multirow{4}{*}{{rf1}} & ERT [\\%] & $\\mathbf{3.81_{0.67}}$ & $8.88_{0.64}$ & $\\underline{5.17_{0.36}}$ \\\\\n",
      " & WSC & $\\mathbf{0.73_{0.01}}$ & $0.61_{0.02}$ & $\\underline{0.73_{0.01}}$ \\\\\n",
      " & Volume & $\\mathbf{0.93_{0.08}}$ & $\\underline{1.30_{0.13}}$ & $1.73_{0.11}$ \\\\\n",
      " & Coverage & $0.90_{0.00}$ & $0.90_{0.00}$ & $0.91_{0.00}$ \\\\\n",
      "\\hline\n",
      "\\multirow{4}{*}{{rf2}} & ERT [\\%] & $\\mathbf{4.38_{0.37}}$ & $8.33_{0.54}$ & $\\underline{5.94_{0.37}}$ \\\\\n",
      " & WSC & $\\underline{0.73_{0.01}}$ & $0.72_{0.01}$ & $\\mathbf{0.73_{0.01}}$ \\\\\n",
      " & Volume & $\\mathbf{1.17_{0.17}}$ & $\\underline{1.55_{0.21}}$ & $2.35_{0.22}$ \\\\\n",
      " & Coverage & $0.90_{0.00}$ & $0.90_{0.00}$ & $0.90_{0.01}$ \\\\\n",
      "\\hline\n",
      "\\multirow{4}{*}{{scm1d}} & ERT [\\%] & $\\mathbf{1.97_{0.45}}$ & $9.21_{0.41}$ & $\\underline{5.92_{0.39}}$ \\\\\n",
      " & WSC & $\\mathbf{0.75_{0.01}}$ & $0.64_{0.01}$ & $\\underline{0.72_{0.02}}$ \\\\\n",
      " & Volume & $\\mathbf{4.31_{0.18}}$ & $\\underline{4.82_{0.16}}$ & $5.33_{0.21}$ \\\\\n",
      " & Coverage & $0.90_{0.01}$ & $0.90_{0.00}$ & $0.90_{0.01}$ \\\\\n",
      "\\hline\n",
      "\\multirow{4}{*}{{scm20d}} & ERT [\\%] & $\\mathbf{2.33_{0.46}}$ & $7.29_{0.43}$ & $\\underline{4.42_{0.39}}$ \\\\\n",
      " & WSC & $\\underline{0.73_{0.01}}$ & $0.71_{0.01}$ & $\\mathbf{0.75_{0.02}}$ \\\\\n",
      " & Volume & $\\mathbf{5.63_{0.31}}$ & $\\underline{6.59_{0.35}}$ & $8.31_{0.44}$ \\\\\n",
      " & Coverage & $0.89_{0.01}$ & $0.90_{0.00}$ & $0.91_{0.01}$ \\\\\n",
      "\\hline\n",
      "\\multirow{4}{*}{{Taxi}} & ERT [\\%] & $\\mathbf{2.09_{0.26}}$ & $6.00_{0.95}$ & $\\underline{5.49_{0.59}}$ \\\\\n",
      " & WSC & $\\mathbf{0.83_{0.01}}$ & $0.74_{0.03}$ & $\\underline{0.76_{0.01}}$ \\\\\n",
      " & Volume & $\\mathbf{3.71_{0.48}}$ & $4.17_{0.42}$ & $\\underline{4.09_{0.45}}$ \\\\\n",
      " & Coverage & $0.90_{0.00}$ & $0.90_{0.00}$ & $0.90_{0.00}$ \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\label{tab:app:results:projection:alpha01}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "alpha = 0.1\n",
    "\n",
    "df = pd.read_csv(\"results_projection.csv\")\n",
    "\n",
    "\n",
    "ert_cols = [c for c in df.columns if c.startswith(\"ERT_\")]\n",
    "df[ert_cols] = df[ert_cols] * 100\n",
    "\n",
    "cols = df.select_dtypes(include=np.number).columns\n",
    "mask = df.groupby([\"alpha\", \"dataset\"])[cols].transform(lambda s: s.isna().sum() >= 2)\n",
    "df[cols] = df[cols].mask(mask)\n",
    "\n",
    "methods = [\"levelset\", \"one\", \"ot\"]\n",
    "\n",
    "# dataset name mapping\n",
    "dataset_map = {\n",
    "    \"biais\": \"Bias\",\n",
    "    \"casp\": \"CASP\",\n",
    "    \"house\": \"House\",\n",
    "    \"rf1\": \"rf1\",\n",
    "    \"rf2\": \"rf2\",\n",
    "    \"taxi\": \"Taxi\",\n",
    "}\n",
    "\n",
    "# method name mapping (for LaTeX header)\n",
    "method_map = {\n",
    "    \"levelset\": \"Mahalanobis\",\n",
    "    \"one\": \"ECM\",\n",
    "    \"ot\": \"OT\",\n",
    "}\n",
    "\n",
    "# keep alpha = 0.1 and compute means\n",
    "res = (\n",
    "    df[df[\"alpha\"] == alpha]\n",
    "    .groupby(\"dataset\")\n",
    "    .agg([\"mean\", \"sem\"])\n",
    ")\n",
    "\n",
    "\n",
    "def format_row_with_std(means, stds, mode=\"min\"):\n",
    "    \"\"\"\n",
    "    mode=\"min\": smallest bold, second smallest underlined\n",
    "    mode=\"max\": largest bold, second largest underlined\n",
    "    mode=None: no highlighting\n",
    "    \"\"\"\n",
    "    means = np.array(means, dtype=float)\n",
    "    stds = np.array(stds, dtype=float)\n",
    "\n",
    "    valid = ~np.isnan(means)\n",
    "\n",
    "    if mode == \"min\":\n",
    "        order = np.argsort(means)\n",
    "    elif mode == \"max\":\n",
    "        order = np.argsort(-means)\n",
    "    else:\n",
    "        order = []\n",
    "\n",
    "    best = order[0] if len(order) > 0 else None\n",
    "    second = order[1] if len(order) > 1 else None\n",
    "\n",
    "    out = []\n",
    "    for i, (m, s) in enumerate(zip(means, stds)):\n",
    "        if np.isnan(m):\n",
    "            out.append(\"N/A\")\n",
    "        else:\n",
    "            val = f\"{m:.2f}_{{{s:.2f}}}\"\n",
    "            if mode is not None:\n",
    "                if i == best:\n",
    "                    val = f\"\\\\mathbf{{{val}}}\"\n",
    "                elif i == second:\n",
    "                    val = f\"\\\\underline{{{val}}}\"\n",
    "            out.append(\"$\"+val+\"$\")\n",
    "    return out\n",
    "\n",
    "\n",
    "# ===== Build LaTeX table =====latex += f\"\\\\caption{{Comparison of methods for $\\\\alpha={alpha}$. Best values in bold, second best underlined.}}\\n\"\n",
    "\n",
    "\n",
    "header_methods = \" & \".join(method_map[m] for m in methods)\n",
    "\n",
    "latex = \"\"\n",
    "latex += \"\\\\begin{table}[ht]\\n\"\n",
    "latex += \"\\\\centering\\n\"\n",
    "latex += \"\\\\small\\n\"\n",
    "latex += f\"\\\\caption{{Comparison of conditional coverage ($\\\\alpha=0.1$) for a projection of the outputs for different conformal methods using the ERT metric (lower is better) and WSC (closer to $0.9$ is better). Best values in bold, second best underlined. N/A indicates that the method failed to produce valid results for the corresponding dataset due to poor conditional density estimation leading to numerical issues in high dimensions Experiments are repeated 10 times, and the index number is the standard error across those 10 experiments.}}\\n\"\n",
    "latex += \"\\\\begin{tabular}{l l \" + \"c \" * len(methods) + \"}\\n\"\n",
    "latex += \"\\\\hline\\n\"\n",
    "latex += f\"Dataset & Metric & {header_methods} \\\\\\\\\\n\"\n",
    "latex += \"\\\\hline\\n\"\n",
    "\n",
    "for dataset_raw, row in res.iterrows():\n",
    "    dataset = dataset_map.get(dataset_raw, dataset_raw)\n",
    "\n",
    "    def get_metric(metric, method):\n",
    "        return (\n",
    "            row[(f\"{metric}_{method}\", \"mean\")] if (f\"{metric}_{method}\", \"mean\") in row else np.nan,\n",
    "            row[(f\"{metric}_{method}\", \"sem\")] if (f\"{metric}_{method}\", \"sem\") in row else np.nan,\n",
    "        )\n",
    "\n",
    "    ert_mean, ert_std = zip(*[get_metric(\"ERT\", m) for m in methods])\n",
    "    vol_mean, vol_std = zip(*[get_metric(\"volume\", m) for m in methods])\n",
    "    wsc_mean, wsc_std = zip(*[get_metric(\"WSC\", m) for m in methods])\n",
    "    cov_mean, cov_std = zip(*[get_metric(\"coverage\", m) for m in methods])\n",
    "\n",
    "    ert_fmt = format_row_with_std(ert_mean, ert_std, mode=\"min\")\n",
    "    vol_fmt = format_row_with_std(vol_mean, vol_std, mode=\"min\")\n",
    "    wsc_fmt = format_row_with_std(wsc_mean, wsc_std, mode=\"max\")\n",
    "    cov_fmt = format_row_with_std(cov_mean, cov_std, mode=None)\n",
    "\n",
    "    \n",
    "    latex += f\"\\\\multirow{{4}}{{*}}{{{{{dataset}}}}} & ERT [\\%] & \" + \" & \".join(ert_fmt) + \" \\\\\\\\\\n\"\n",
    "    latex += f\" & WSC & \" + \" & \".join(wsc_fmt) + \" \\\\\\\\\\n\"\n",
    "    latex += f\" & Volume & \" + \" & \".join(vol_fmt) + \" \\\\\\\\\\n\"\n",
    "    latex += f\" & Coverage & \" + \" & \".join(cov_fmt) + \" \\\\\\\\\\n\"\n",
    "    latex += \"\\\\hline\\n\"\n",
    "\n",
    "latex += \"\\\\end{tabular}\\n\"\n",
    "latex += \"\\\\label{tab:app:results:projection:alpha01}\\n\"\n",
    "latex += \"\\\\end{table}\\n\"\n",
    "\n",
    "print(latex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5eb591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[ht]\n",
      "\\centering\n",
      "\\small\n",
      "\\caption{Comparison of conditional coverage ($\\alpha=0.05$) for a projection of the outputs for different conformal methods using the ERT metric (lower is better) and WSC (closer to $0.9$ is better). Best values in bold, second best underlined. N/A indicates that the method failed to produce valid results for the corresponding dataset due to poor conditional density estimation leading to numerical issues in high dimensions Experiments are repeated 10 times, and the index number is the standard error across those 10 experiments.}\n",
      "\\begin{tabular}{l l c c c }\n",
      "\\hline\n",
      "Dataset & Metric & Mahalanobis & ECM & OT \\\\\n",
      "\\hline\n",
      "\\multirow{4}{*}{{Bias}} & ERT [\\%] & $\\mathbf{0.93_{0.29}}$ & $\\underline{2.20_{0.29}}$ & $2.35_{0.40}$ \\\\\n",
      " & WSC & $0.74_{0.01}$ & $\\underline{0.75_{0.01}}$ & $\\mathbf{0.77_{0.02}}$ \\\\\n",
      " & Volume & $\\mathbf{1.64_{0.18}}$ & $\\underline{1.96_{0.20}}$ & $2.47_{0.26}$ \\\\\n",
      " & Coverage & $0.95_{0.00}$ & $0.95_{0.00}$ & $0.96_{0.01}$ \\\\\n",
      "\\hline\n",
      "\\multirow{4}{*}{{CASP}} & ERT [\\%] & $\\mathbf{0.82_{0.17}}$ & $2.72_{0.15}$ & $\\underline{2.39_{0.14}}$ \\\\\n",
      " & WSC & $\\mathbf{0.87_{0.00}}$ & $0.82_{0.01}$ & $\\underline{0.84_{0.01}}$ \\\\\n",
      " & Volume & $\\mathbf{2.33_{0.28}}$ & $\\underline{2.62_{0.31}}$ & $2.91_{0.30}$ \\\\\n",
      " & Coverage & $0.95_{0.00}$ & $0.95_{0.00}$ & $0.95_{0.00}$ \\\\\n",
      "\\hline\n",
      "\\multirow{4}{*}{{House}} & ERT [\\%] & $\\mathbf{1.87_{0.15}}$ & $4.28_{0.31}$ & $\\underline{3.62_{0.33}}$ \\\\\n",
      " & WSC & $\\mathbf{0.80_{0.01}}$ & $0.76_{0.01}$ & $\\underline{0.78_{0.01}}$ \\\\\n",
      " & Volume & $\\mathbf{2.34_{0.21}}$ & $\\underline{3.23_{0.32}}$ & $3.67_{0.35}$ \\\\\n",
      " & Coverage & $0.95_{0.00}$ & $0.95_{0.00}$ & $0.95_{0.00}$ \\\\\n",
      "\\hline\n",
      "\\multirow{4}{*}{{rf1}} & ERT [\\%] & $\\mathbf{1.81_{0.42}}$ & $5.72_{0.30}$ & $\\underline{2.70_{0.39}}$ \\\\\n",
      " & WSC & $\\underline{0.75_{0.01}}$ & $0.59_{0.03}$ & $\\mathbf{0.77_{0.01}}$ \\\\\n",
      " & Volume & $\\mathbf{1.08_{0.09}}$ & $\\underline{1.94_{0.18}}$ & $2.13_{0.14}$ \\\\\n",
      " & Coverage & $0.95_{0.00}$ & $0.95_{0.00}$ & $0.96_{0.00}$ \\\\\n",
      "\\hline\n",
      "\\multirow{4}{*}{{rf2}} & ERT [\\%] & $\\mathbf{1.82_{0.40}}$ & $5.08_{0.35}$ & $\\underline{3.28_{0.30}}$ \\\\\n",
      " & WSC & $\\underline{0.75_{0.01}}$ & $0.73_{0.01}$ & $\\mathbf{0.77_{0.02}}$ \\\\\n",
      " & Volume & $\\mathbf{1.37_{0.19}}$ & $\\underline{2.10_{0.28}}$ & $3.15_{0.31}$ \\\\\n",
      " & Coverage & $0.95_{0.00}$ & $0.95_{0.00}$ & $0.96_{0.01}$ \\\\\n",
      "\\hline\n",
      "\\multirow{4}{*}{{scm1d}} & ERT [\\%] & $\\mathbf{0.91_{0.40}}$ & $5.38_{0.22}$ & $\\underline{3.43_{0.21}}$ \\\\\n",
      " & WSC & $\\mathbf{0.78_{0.01}}$ & $0.60_{0.02}$ & $\\underline{0.75_{0.02}}$ \\\\\n",
      " & Volume & $\\mathbf{5.20_{0.22}}$ & $6.28_{0.21}$ & $\\underline{6.15_{0.35}}$ \\\\\n",
      " & Coverage & $0.95_{0.00}$ & $0.95_{0.00}$ & $0.96_{0.00}$ \\\\\n",
      "\\hline\n",
      "\\multirow{4}{*}{{scm20d}} & ERT [\\%] & $\\mathbf{1.34_{0.33}}$ & $4.91_{0.25}$ & $\\underline{2.35_{0.33}}$ \\\\\n",
      " & WSC & $\\underline{0.77_{0.01}}$ & $0.75_{0.01}$ & $\\mathbf{0.79_{0.02}}$ \\\\\n",
      " & Volume & $\\mathbf{6.67_{0.37}}$ & $\\underline{8.53_{0.46}}$ & $9.91_{0.72}$ \\\\\n",
      " & Coverage & $0.95_{0.00}$ & $0.96_{0.00}$ & $0.96_{0.01}$ \\\\\n",
      "\\hline\n",
      "\\multirow{4}{*}{{Taxi}} & ERT [\\%] & $\\mathbf{1.22_{0.12}}$ & $3.76_{0.58}$ & $\\underline{3.27_{0.27}}$ \\\\\n",
      " & WSC & $\\mathbf{0.87_{0.01}}$ & $0.75_{0.03}$ & $\\underline{0.78_{0.01}}$ \\\\\n",
      " & Volume & $\\mathbf{4.49_{0.59}}$ & $5.13_{0.48}$ & $\\underline{4.98_{0.48}}$ \\\\\n",
      " & Coverage & $0.95_{0.00}$ & $0.95_{0.00}$ & $0.95_{0.00}$ \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\label{tab:app:results:projection:alpha005}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "df = pd.read_csv(\"results_projection.csv\")\n",
    "\n",
    "\n",
    "ert_cols = [c for c in df.columns if c.startswith(\"ERT_\")]\n",
    "df[ert_cols] = df[ert_cols] * 100\n",
    "\n",
    "cols = df.select_dtypes(include=np.number).columns\n",
    "mask = df.groupby([\"alpha\", \"dataset\"])[cols].transform(lambda s: s.isna().sum() >= 2)\n",
    "df[cols] = df[cols].mask(mask)\n",
    "\n",
    "methods = [\"levelset\", \"one\", \"ot\"]\n",
    "\n",
    "# dataset name mapping\n",
    "dataset_map = {\n",
    "    \"biais\": \"Bias\",\n",
    "    \"casp\": \"CASP\",\n",
    "    \"house\": \"House\",\n",
    "    \"rf1\": \"rf1\",\n",
    "    \"rf2\": \"rf2\",\n",
    "    \"taxi\": \"Taxi\",\n",
    "}\n",
    "\n",
    "# method name mapping (for LaTeX header)\n",
    "method_map = {\n",
    "    \"levelset\": \"Mahalanobis\",\n",
    "    \"one\": \"ECM\",\n",
    "    \"ot\": \"OT\",\n",
    "}\n",
    "\n",
    "# keep alpha = 0.1 and compute means\n",
    "res = (\n",
    "    df[df[\"alpha\"] == alpha]\n",
    "    .groupby(\"dataset\")\n",
    "    .agg([\"mean\", \"sem\"])\n",
    ")\n",
    "\n",
    "\n",
    "def format_row_with_std(means, stds, mode=\"min\"):\n",
    "    \"\"\"\n",
    "    mode=\"min\": smallest bold, second smallest underlined\n",
    "    mode=\"max\": largest bold, second largest underlined\n",
    "    mode=None: no highlighting\n",
    "    \"\"\"\n",
    "    means = np.array(means, dtype=float)\n",
    "    stds = np.array(stds, dtype=float)\n",
    "\n",
    "    valid = ~np.isnan(means)\n",
    "\n",
    "    if mode == \"min\":\n",
    "        order = np.argsort(means)\n",
    "    elif mode == \"max\":\n",
    "        order = np.argsort(-means)\n",
    "    else:\n",
    "        order = []\n",
    "\n",
    "    best = order[0] if len(order) > 0 else None\n",
    "    second = order[1] if len(order) > 1 else None\n",
    "\n",
    "    out = []\n",
    "    for i, (m, s) in enumerate(zip(means, stds)):\n",
    "        if np.isnan(m):\n",
    "            out.append(\"N/A\")\n",
    "        else:\n",
    "            val = f\"{m:.2f}_{{{s:.2f}}}\"\n",
    "            if mode is not None:\n",
    "                if i == best:\n",
    "                    val = f\"\\\\mathbf{{{val}}}\"\n",
    "                elif i == second:\n",
    "                    val = f\"\\\\underline{{{val}}}\"\n",
    "            out.append(\"$\"+val+\"$\")\n",
    "    return out\n",
    "\n",
    "\n",
    "# ===== Build LaTeX table =====latex += f\"\\\\caption{{Comparison of methods for $\\\\alpha={alpha}$. Best values in bold, second best underlined.}}\\n\"\n",
    "\n",
    "\n",
    "header_methods = \" & \".join(method_map[m] for m in methods)\n",
    "\n",
    "latex = \"\"\n",
    "latex += \"\\\\begin{table}[ht]\\n\"\n",
    "latex += \"\\\\centering\\n\"\n",
    "latex += \"\\\\small\\n\"\n",
    "latex += f\"\\\\caption{{Comparison of conditional coverage ($\\\\alpha=0.05$) for a projection of the outputs for different conformal methods using the ERT metric (lower is better) and WSC (closer to $0.9$ is better). Best values in bold, second best underlined. N/A indicates that the method failed to produce valid results for the corresponding dataset due to poor conditional density estimation leading to numerical issues in high dimensions Experiments are repeated 10 times, and the index number is the standard error across those 10 experiments.}}\\n\"\n",
    "latex += \"\\\\begin{tabular}{l l \" + \"c \" * len(methods) + \"}\\n\"\n",
    "latex += \"\\\\hline\\n\"\n",
    "latex += f\"Dataset & Metric & {header_methods} \\\\\\\\\\n\"\n",
    "latex += \"\\\\hline\\n\"\n",
    "\n",
    "for dataset_raw, row in res.iterrows():\n",
    "    dataset = dataset_map.get(dataset_raw, dataset_raw)\n",
    "\n",
    "    def get_metric(metric, method):\n",
    "        return (\n",
    "            row[(f\"{metric}_{method}\", \"mean\")] if (f\"{metric}_{method}\", \"mean\") in row else np.nan,\n",
    "            row[(f\"{metric}_{method}\", \"sem\")] if (f\"{metric}_{method}\", \"sem\") in row else np.nan,\n",
    "        )\n",
    "\n",
    "    ert_mean, ert_std = zip(*[get_metric(\"ERT\", m) for m in methods])\n",
    "    vol_mean, vol_std = zip(*[get_metric(\"volume\", m) for m in methods])\n",
    "    wsc_mean, wsc_std = zip(*[get_metric(\"WSC\", m) for m in methods])\n",
    "    cov_mean, cov_std = zip(*[get_metric(\"coverage\", m) for m in methods])\n",
    "\n",
    "    ert_fmt = format_row_with_std(ert_mean, ert_std, mode=\"min\")\n",
    "    vol_fmt = format_row_with_std(vol_mean, vol_std, mode=\"min\")\n",
    "    wsc_fmt = format_row_with_std(wsc_mean, wsc_std, mode=\"max\")\n",
    "    cov_fmt = format_row_with_std(cov_mean, cov_std, mode=None)\n",
    "\n",
    "    \n",
    "    latex += f\"\\\\multirow{{4}}{{*}}{{{{{dataset}}}}} & ERT [\\%] & \" + \" & \".join(ert_fmt) + \" \\\\\\\\\\n\"\n",
    "    latex += f\" & WSC & \" + \" & \".join(wsc_fmt) + \" \\\\\\\\\\n\"\n",
    "    latex += f\" & Volume & \" + \" & \".join(vol_fmt) + \" \\\\\\\\\\n\"\n",
    "    latex += f\" & Coverage & \" + \" & \".join(cov_fmt) + \" \\\\\\\\\\n\"\n",
    "    latex += \"\\\\hline\\n\"\n",
    "\n",
    "latex += \"\\\\end{tabular}\\n\"\n",
    "latex += \"\\\\label{tab:app:results:projection:alpha005}\\n\"\n",
    "latex += \"\\\\end{table}\\n\"\n",
    "\n",
    "print(latex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e01c0b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
