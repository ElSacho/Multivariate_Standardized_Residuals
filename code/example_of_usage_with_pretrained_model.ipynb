{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data and declare hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from utils import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from data_loading import *\n",
    "\n",
    "from standardized_residuals import StandardizedResiduals\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (32010, 7) Y_train shape: (32010, 3)\n",
      "X_cal shape: (4573, 7) Y_cal shape: (4573, 3)\n",
      "X_test shape: (4574, 7) Y_test shape: (4574, 3)\n",
      "X_stop shape: (4573, 7) Y_stop shape: (4573, 3)\n"
     ]
    }
   ],
   "source": [
    "load_path = \"../data/processed_data_3Dmin/casp.npz\"\n",
    "\n",
    "X, Y = load_data(load_path)\n",
    "\n",
    "normalize = True\n",
    "splits = [0.7, 0.1, 0.1, 0.1]\n",
    "\n",
    "subsets = split_and_preprocess(X, Y, splits=splits, normalize=normalize)\n",
    "\n",
    "x_train, y_train, x_calibration, y_calibration, x_test, y_test, x_stop, y_stop = subsets[\"X_train\"], subsets[\"Y_train\"], subsets[\"X_calibration\"], subsets[\"Y_calibration\"], subsets[\"X_test\"], subsets[\"Y_test\"], subsets[\"X_stop\"], subsets[\"Y_stop\"]\n",
    "\n",
    "print(\"X_train shape:\", x_train.shape, \"Y_train shape:\", y_train.shape)\n",
    "print(\"X_cal shape:\", x_calibration.shape, \"Y_cal shape:\", y_calibration.shape)\n",
    "print(\"X_test shape:\", x_test.shape, \"Y_test shape:\", y_test.shape)\n",
    "print(\"X_stop shape:\", x_stop.shape, \"Y_stop shape:\", y_stop.shape)\n",
    "\n",
    "\n",
    "input_dim = x_train.shape[1]\n",
    "output_dim = y_train.shape[1]\n",
    "\n",
    "n_train = x_train.shape[0]\n",
    "n_test = x_test.shape[0]\n",
    "n_calibration = x_calibration.shape[0]\n",
    "n_stop = x_stop.shape[0]\n",
    "\n",
    "dtype = torch.float32\n",
    "\n",
    "x_train_tensor = torch.tensor(x_train, dtype=dtype)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=dtype)\n",
    "x_stop_tensor = torch.tensor(x_stop, dtype=dtype)\n",
    "y_stop_tensor = torch.tensor(y_stop, dtype=dtype)\n",
    "x_calibration_tensor = torch.tensor(x_calibration, dtype=dtype)\n",
    "y_calibration_tensor = torch.tensor(y_calibration, dtype=dtype)\n",
    "x_test_tensor = torch.tensor(x_test, dtype=dtype)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=dtype)\n",
    "\n",
    "alpha = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZeroPred:\n",
    "    def __init__(self, y_dim):\n",
    "        self.y_dim = y_dim\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return np.zeros((len(x), self.y_dim))\n",
    "\n",
    "center_model = ZeroPred(output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Avg NLL Loss = 0.2670 -- Stop loss: 0.1523 -- Best Stop Loss: inf\n",
      "Epoch 2: Avg NLL Loss = 0.0900 -- Stop loss: 0.0989 -- Best Stop Loss: 0.15226999519171414\n",
      "Epoch 3: Avg NLL Loss = 0.0349 -- Stop loss: 0.0134 -- Best Stop Loss: 0.09888782586667921\n",
      "Epoch 4: Avg NLL Loss = 0.0247 -- Stop loss: 0.0158 -- Best Stop Loss: 0.013418140736493197\n",
      "Epoch 5: Avg NLL Loss = -0.0168 -- Stop loss: -0.0374 -- Best Stop Loss: 0.013418140736493197\n",
      "Epoch 6: Avg NLL Loss = -0.0367 -- Stop loss: 0.0472 -- Best Stop Loss: -0.03735227275874231\n",
      "Epoch 7: Avg NLL Loss = -0.0383 -- Stop loss: 0.0183 -- Best Stop Loss: -0.03735227275874231\n",
      "Epoch 8: Avg NLL Loss = -0.0613 -- Stop loss: -0.0083 -- Best Stop Loss: -0.03735227275874231\n",
      "Epoch 9: Avg NLL Loss = -0.0699 -- Stop loss: -0.0471 -- Best Stop Loss: -0.03735227275874231\n",
      "Epoch 10: Avg NLL Loss = -0.0868 -- Stop loss: -0.0504 -- Best Stop Loss: -0.04709116132421927\n",
      "Epoch 11: Avg NLL Loss = -0.0961 -- Stop loss: -0.1067 -- Best Stop Loss: -0.050357776270671326\n",
      "Epoch 12: Avg NLL Loss = -0.1140 -- Stop loss: -0.0655 -- Best Stop Loss: -0.10668842121958733\n",
      "Epoch 13: Avg NLL Loss = -0.1221 -- Stop loss: -0.1130 -- Best Stop Loss: -0.10668842121958733\n",
      "Epoch 14: Avg NLL Loss = -0.1411 -- Stop loss: -0.0681 -- Best Stop Loss: -0.11296360645365049\n",
      "Epoch 15: Avg NLL Loss = -0.1317 -- Stop loss: -0.1186 -- Best Stop Loss: -0.11296360645365049\n",
      "Epoch 16: Avg NLL Loss = -0.1360 -- Stop loss: -0.0610 -- Best Stop Loss: -0.11859985237771814\n",
      "Epoch 17: Avg NLL Loss = -0.1518 -- Stop loss: -0.0988 -- Best Stop Loss: -0.11859985237771814\n",
      "Epoch 18: Avg NLL Loss = -0.1583 -- Stop loss: -0.0955 -- Best Stop Loss: -0.11859985237771814\n",
      "Epoch 19: Avg NLL Loss = -0.1672 -- Stop loss: -0.0781 -- Best Stop Loss: -0.11859985237771814\n",
      "Epoch 20: Avg NLL Loss = -0.1783 -- Stop loss: -0.1328 -- Best Stop Loss: -0.11859985237771814\n",
      "Epoch 21: Avg NLL Loss = -0.1830 -- Stop loss: -0.1432 -- Best Stop Loss: -0.13279174952083952\n",
      "Epoch 22: Avg NLL Loss = -0.1810 -- Stop loss: -0.0614 -- Best Stop Loss: -0.1432304703272306\n",
      "Epoch 23: Avg NLL Loss = -0.1758 -- Stop loss: -0.1326 -- Best Stop Loss: -0.1432304703272306\n",
      "Epoch 24: Avg NLL Loss = -0.1543 -- Stop loss: -0.1313 -- Best Stop Loss: -0.1432304703272306\n",
      "Epoch 25: Avg NLL Loss = -0.2019 -- Stop loss: -0.1363 -- Best Stop Loss: -0.1432304703272306\n",
      "Epoch 26: Avg NLL Loss = -0.1952 -- Stop loss: -0.0737 -- Best Stop Loss: -0.1432304703272306\n",
      "Epoch 27: Avg NLL Loss = -0.1790 -- Stop loss: -0.1101 -- Best Stop Loss: -0.1432304703272306\n",
      "Epoch 28: Avg NLL Loss = -0.2093 -- Stop loss: -0.1318 -- Best Stop Loss: -0.1432304703272306\n",
      "Epoch 29: Avg NLL Loss = -0.1752 -- Stop loss: -0.1759 -- Best Stop Loss: -0.1432304703272306\n",
      "Best stop loss achieved: -0.1759\n"
     ]
    }
   ],
   "source": [
    "seed_everything(42)\n",
    "\n",
    "hidden_dim = 128\n",
    "num_layers = 3\n",
    "batch_size = 32\n",
    "num_epochs = 30\n",
    "lr = 1e-3\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_train_tensor, y_train_tensor), batch_size= batch_size, shuffle=True)\n",
    "stoploader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_stop_tensor, y_stop_tensor), batch_size= batch_size, shuffle=True)\n",
    "\n",
    "standardized_residuals = StandardizedResiduals(input_dim, \n",
    "                            output_dim,\n",
    "                            hidden_dim = hidden_dim,\n",
    "                            num_layers = num_layers,\n",
    "                            center_model = center_model\n",
    "                            )\n",
    "\n",
    "standardized_residuals.fit(trainloader, \n",
    "                    stoploader,\n",
    "                    num_epochs=num_epochs,\n",
    "                    lr=lr,\n",
    "                    verbose = 2\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, Sigma = standardized_residuals.get_distribution(x_test_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.511889457702637"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardized_residuals.conformalize(x=x_calibration_tensor, y=y_calibration_tensor, alpha = alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage: 0.9121119379997253\n",
      "Average Volume: 1.5569067001342773\n"
     ]
    }
   ],
   "source": [
    "coverage = standardized_residuals.get_coverage(x_test_tensor, y_test_tensor)\n",
    "volumes  = standardized_residuals.get_average_volume(x_test_tensor)\n",
    "\n",
    "print(\"Coverage:\", coverage)\n",
    "print(\"Average Volume:\", volumes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revealed outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5451841354370117"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_knowned = np.array([0])\n",
    "\n",
    "standardized_residuals.conformalize_revealed(idx_revealed = idx_knowned,\n",
    "                                            x = x_calibration_tensor, \n",
    "                                            y = y_calibration_tensor, \n",
    "                                            alpha = alpha\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO : checker si la definition du q_alpha reste la meme.\n",
      "Coverage: 0.914516806602478\n",
      "Average Volume: 1.5590709447860718\n"
     ]
    }
   ],
   "source": [
    "coverage = standardized_residuals.get_coverage_revealed(x_test_tensor, y_test_tensor)\n",
    "volumes  = standardized_residuals.get_average_volume_revealed(x_test_tensor, y_test_tensor[:, idx_knowned])\n",
    "\n",
    "print(\"Coverage:\", coverage)\n",
    "print(\"Average Volume:\", volumes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projection of the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.126266956329346"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projection_matrix_tensor =  torch.randn((2, output_dim), dtype=dtype)\n",
    "\n",
    "standardized_residuals.conformalize_projection(\n",
    "                                            projection_matrix = projection_matrix_tensor,\n",
    "                                            x = x_calibration_tensor, \n",
    "                                            y = y_calibration_tensor, \n",
    "                                            alpha = alpha\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage: 0.9112374186515808\n",
      "Average Volume: 1.7222936153411865\n"
     ]
    }
   ],
   "source": [
    "coverage = standardized_residuals.get_coverage_projection(x_test_tensor, y_test_tensor)\n",
    "volumes  = standardized_residuals.get_average_volume_projection(x_test_tensor)\n",
    "\n",
    "print(\"Coverage:\", coverage)\n",
    "print(\"Average Volume:\", volumes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add NaN values to the calibration and test sets\n",
    "\n",
    "y_calibration_nan = add_nan(y_calibration, min_nan=1, max_nan=output_dim-1)\n",
    "y_calibration_nan_tensor = torch.tensor(y_calibration_nan, dtype=dtype)\n",
    "\n",
    "y_test_nan = add_nan(y_test, min_nan=1, max_nan=output_dim-1)\n",
    "y_test_nan_tensor = torch.tensor(y_test_nan, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8660470843315125"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardized_residuals.conformalize_missing(x = x_calibration_tensor,\n",
    "                                            y = y_calibration_nan_tensor, \n",
    "                                            alpha = alpha\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage with NaN: 0.9079580307006836\n",
      "Coverage full vector: 0.9121119379997253\n"
     ]
    }
   ],
   "source": [
    "coverage_with_nan    = standardized_residuals.get_coverage_missing(x_test_tensor, y_test_nan_tensor)\n",
    "coverage_full_vector = standardized_residuals.get_coverage(x_test_tensor, y_test_tensor)\n",
    "\n",
    "print(\"Coverage with NaN:\", coverage_with_nan)\n",
    "print(\"Coverage full vector:\", coverage_full_vector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
