{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data and declare hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from utils import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from data_loading import *\n",
    "\n",
    "from standardized_residuals import StandardizedResiduals\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (32010, 7) Y_train shape: (32010, 3)\n",
      "X_cal shape: (4573, 7) Y_cal shape: (4573, 3)\n",
      "X_test shape: (4574, 7) Y_test shape: (4574, 3)\n",
      "X_stop shape: (4573, 7) Y_stop shape: (4573, 3)\n"
     ]
    }
   ],
   "source": [
    "load_path = \"../data/processed_data_3Dmin/casp.npz\"\n",
    "\n",
    "X, Y = load_data(load_path)\n",
    "\n",
    "normalize = True\n",
    "splits = [0.7, 0.1, 0.1, 0.1]\n",
    "\n",
    "subsets = split_and_preprocess(X, Y, splits=splits, normalize=normalize)\n",
    "\n",
    "x_train, y_train, x_calibration, y_calibration, x_test, y_test, x_stop, y_stop = subsets[\"X_train\"], subsets[\"Y_train\"], subsets[\"X_calibration\"], subsets[\"Y_calibration\"], subsets[\"X_test\"], subsets[\"Y_test\"], subsets[\"X_stop\"], subsets[\"Y_stop\"]\n",
    "\n",
    "print(\"X_train shape:\", x_train.shape, \"Y_train shape:\", y_train.shape)\n",
    "print(\"X_cal shape:\", x_calibration.shape, \"Y_cal shape:\", y_calibration.shape)\n",
    "print(\"X_test shape:\", x_test.shape, \"Y_test shape:\", y_test.shape)\n",
    "print(\"X_stop shape:\", x_stop.shape, \"Y_stop shape:\", y_stop.shape)\n",
    "\n",
    "\n",
    "input_dim = x_train.shape[1]\n",
    "output_dim = y_train.shape[1]\n",
    "\n",
    "n_train = x_train.shape[0]\n",
    "n_test = x_test.shape[0]\n",
    "n_calibration = x_calibration.shape[0]\n",
    "n_stop = x_stop.shape[0]\n",
    "\n",
    "dtype = torch.float32\n",
    "\n",
    "x_train_tensor = torch.tensor(x_train, dtype=dtype)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=dtype)\n",
    "x_stop_tensor = torch.tensor(x_stop, dtype=dtype)\n",
    "y_stop_tensor = torch.tensor(y_stop, dtype=dtype)\n",
    "x_calibration_tensor = torch.tensor(x_calibration, dtype=dtype)\n",
    "y_calibration_tensor = torch.tensor(y_calibration, dtype=dtype)\n",
    "x_test_tensor = torch.tensor(x_test, dtype=dtype)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=dtype)\n",
    "\n",
    "alpha = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sbraun/Desktop/Gaussian_Conformal_Prediction_V2/code/standardized_residuals.py:266: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:2259.)\n",
      "  z = torch.triangular_solve(diff, L, upper=False)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Avg NLL Loss = -0.4964 -- Stop loss: -0.6929 -- Best Stop Loss: inf\n",
      "Epoch 2: Avg NLL Loss = -0.7229 -- Stop loss: -0.8217 -- Best Stop Loss: -0.692947858488643\n",
      "Epoch 3: Avg NLL Loss = -0.8363 -- Stop loss: -0.8878 -- Best Stop Loss: -0.8216597942205576\n",
      "Epoch 4: Avg NLL Loss = -0.8327 -- Stop loss: -0.8242 -- Best Stop Loss: -0.8877824727263484\n",
      "Epoch 5: Avg NLL Loss = -0.9041 -- Stop loss: -0.9616 -- Best Stop Loss: -0.8877824727263484\n",
      "Epoch 6: Avg NLL Loss = -0.9206 -- Stop loss: -0.8484 -- Best Stop Loss: -0.9615701879863139\n",
      "Epoch 7: Avg NLL Loss = -0.9504 -- Stop loss: -0.7536 -- Best Stop Loss: -0.9615701879863139\n",
      "Epoch 8: Avg NLL Loss = -0.9705 -- Stop loss: -1.0128 -- Best Stop Loss: -0.9615701879863139\n",
      "Epoch 9: Avg NLL Loss = -0.9753 -- Stop loss: -0.9826 -- Best Stop Loss: -1.0127524775224965\n",
      "Epoch 10: Avg NLL Loss = -0.9984 -- Stop loss: -0.8751 -- Best Stop Loss: -1.0127524775224965\n",
      "Epoch 11: Avg NLL Loss = -1.0027 -- Stop loss: -1.0479 -- Best Stop Loss: -1.0127524775224965\n",
      "Epoch 12: Avg NLL Loss = -1.0314 -- Stop loss: -1.0677 -- Best Stop Loss: -1.0478856701117296\n",
      "Epoch 13: Avg NLL Loss = -1.0381 -- Stop loss: -1.0223 -- Best Stop Loss: -1.0676843168643804\n",
      "Epoch 14: Avg NLL Loss = -1.0573 -- Stop loss: -1.0550 -- Best Stop Loss: -1.0676843168643804\n",
      "Epoch 15: Avg NLL Loss = -1.0581 -- Stop loss: -1.0591 -- Best Stop Loss: -1.0676843168643804\n",
      "Epoch 16: Avg NLL Loss = -1.0829 -- Stop loss: -1.0101 -- Best Stop Loss: -1.0676843168643804\n",
      "Epoch 17: Avg NLL Loss = -1.0787 -- Stop loss: -1.1095 -- Best Stop Loss: -1.0676843168643804\n",
      "Epoch 18: Avg NLL Loss = -1.1153 -- Stop loss: -1.0678 -- Best Stop Loss: -1.109475610973118\n",
      "Epoch 19: Avg NLL Loss = -1.1047 -- Stop loss: -1.0766 -- Best Stop Loss: -1.109475610973118\n",
      "Epoch 20: Avg NLL Loss = -1.1133 -- Stop loss: -1.1114 -- Best Stop Loss: -1.109475610973118\n",
      "Epoch 21: Avg NLL Loss = -1.1182 -- Stop loss: -1.0730 -- Best Stop Loss: -1.1114101165553907\n",
      "Epoch 22: Avg NLL Loss = -1.1139 -- Stop loss: -1.1256 -- Best Stop Loss: -1.1114101165553907\n",
      "Epoch 23: Avg NLL Loss = -1.1083 -- Stop loss: -1.1373 -- Best Stop Loss: -1.12555940188728\n",
      "Epoch 24: Avg NLL Loss = -1.1250 -- Stop loss: -1.0914 -- Best Stop Loss: -1.1373182253820913\n",
      "Epoch 25: Avg NLL Loss = -1.1545 -- Stop loss: -1.1343 -- Best Stop Loss: -1.1373182253820913\n",
      "Epoch 26: Avg NLL Loss = -1.1392 -- Stop loss: -1.0705 -- Best Stop Loss: -1.1373182253820913\n",
      "Epoch 27: Avg NLL Loss = -1.1581 -- Stop loss: -1.1581 -- Best Stop Loss: -1.1373182253820913\n",
      "Epoch 28: Avg NLL Loss = -1.1708 -- Stop loss: -1.0944 -- Best Stop Loss: -1.1581302555082562\n",
      "Epoch 29: Avg NLL Loss = -1.1681 -- Stop loss: -1.1865 -- Best Stop Loss: -1.1581302555082562\n",
      "Best stop loss achieved: -1.1865\n"
     ]
    }
   ],
   "source": [
    "seed_everything(42)\n",
    "\n",
    "hidden_dim = 128\n",
    "num_layers = 3\n",
    "batch_size = 32\n",
    "num_epochs = 30\n",
    "lr = 1e-3\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_train_tensor, y_train_tensor), batch_size= batch_size, shuffle=True)\n",
    "stoploader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_stop_tensor, y_stop_tensor), batch_size= batch_size, shuffle=True)\n",
    "\n",
    "standardized_residuals = StandardizedResiduals(input_dim, \n",
    "                            output_dim,\n",
    "                            hidden_dim = hidden_dim,\n",
    "                            num_layers = num_layers\n",
    "                            )\n",
    "\n",
    "standardized_residuals.fit(trainloader, \n",
    "                    stoploader,\n",
    "                    num_epochs=num_epochs,\n",
    "                    lr=lr,\n",
    "                    verbose = 2\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.511889457702637"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardized_residuals.conformalize(x=x_calibration_tensor, y=y_calibration_tensor, alpha = alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage: 0.9121119379997253\n",
      "Average Volume: 1.5569067001342773\n"
     ]
    }
   ],
   "source": [
    "coverage = standardized_residuals.get_coverage(x_test_tensor, y_test_tensor)\n",
    "volumes  = standardized_residuals.get_average_volume(x_test_tensor)\n",
    "\n",
    "print(\"Coverage:\", coverage)\n",
    "print(\"Average Volume:\", volumes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revealed outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5451841354370117"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_knowned = np.array([0])\n",
    "\n",
    "standardized_residuals.conformalize_revealed(idx_revealed = idx_knowned,\n",
    "                                            x = x_calibration_tensor, \n",
    "                                            y = y_calibration_tensor, \n",
    "                                            alpha = alpha\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO : checker si la definition du q_alpha reste la meme.\n",
      "Coverage: 0.914516806602478\n",
      "Average Volume: 1.5590709447860718\n"
     ]
    }
   ],
   "source": [
    "coverage = standardized_residuals.get_coverage_revealed(x_test_tensor, y_test_tensor)\n",
    "volumes  = standardized_residuals.get_average_volume_revealed(x_test_tensor, y_test_tensor[:, idx_knowned])\n",
    "\n",
    "print(\"Coverage:\", coverage)\n",
    "print(\"Average Volume:\", volumes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projection of the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.126266956329346"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projection_matrix_tensor =  torch.randn((2, output_dim), dtype=dtype)\n",
    "\n",
    "standardized_residuals.conformalize_projection(\n",
    "                                            projection_matrix = projection_matrix_tensor,\n",
    "                                            x = x_calibration_tensor, \n",
    "                                            y = y_calibration_tensor, \n",
    "                                            alpha = alpha\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage: 0.9112374186515808\n",
      "Average Volume: 1.7222936153411865\n"
     ]
    }
   ],
   "source": [
    "coverage = standardized_residuals.get_coverage_projection(x_test_tensor, y_test_tensor)\n",
    "volumes  = standardized_residuals.get_average_volume_projection(x_test_tensor)\n",
    "\n",
    "print(\"Coverage:\", coverage)\n",
    "print(\"Average Volume:\", volumes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add NaN values to the calibration and test sets\n",
    "\n",
    "y_calibration_nan = add_nan(y_calibration, min_nan=1, max_nan=output_dim-1)\n",
    "y_calibration_nan_tensor = torch.tensor(y_calibration_nan, dtype=dtype)\n",
    "\n",
    "y_test_nan = add_nan(y_test, min_nan=1, max_nan=output_dim-1)\n",
    "y_test_nan_tensor = torch.tensor(y_test_nan, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8660470843315125"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardized_residuals.conformalize_missing(x = x_calibration_tensor,\n",
    "                                            y = y_calibration_nan_tensor, \n",
    "                                            alpha = alpha\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage with NaN: 0.9079580307006836\n",
      "Coverage full vector: 0.9121119379997253\n"
     ]
    }
   ],
   "source": [
    "coverage_with_nan    = standardized_residuals.get_coverage_missing(x_test_tensor, y_test_nan_tensor)\n",
    "coverage_full_vector = standardized_residuals.get_coverage(x_test_tensor, y_test_tensor)\n",
    "\n",
    "print(\"Coverage with NaN:\", coverage_with_nan)\n",
    "print(\"Coverage full vector:\", coverage_full_vector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
